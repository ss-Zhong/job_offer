#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿®å¤ç‰ˆå±‚æ¬¡åŒ–æŸå¤±å‡½æ•°å¯¹æ¯”å®éªŒ
é›†æˆä¸­æ–‡é¢„å¤„ç†å’Œæ™ºèƒ½æ•°æ®åˆ’åˆ†
"""

import os
import sys
import time
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import json
import warnings
import torch
from collections import Counter

warnings.filterwarnings('ignore')

# å¯¼å…¥åŸæœ‰æ¨¡å—
if __name__ == '__main__':
    # ç¡®ä¿å¯ä»¥æ‰¾åˆ°å±‚æ¬¡åŒ–å·¥å…·
    sys.path.append('.')
    
    # å°è¯•å¯¼å…¥å±‚æ¬¡åŒ–åŠŸèƒ½
    try:
        from hierarchical_utils import create_hierarchical_components, HierarchicalLoss
        HIERARCHICAL_AVAILABLE = True
        print("âœ… å±‚æ¬¡åŒ–åŠŸèƒ½å¯ç”¨")
    except ImportError as e:
        HIERARCHICAL_AVAILABLE = False
        print(f"âš ï¸ å±‚æ¬¡åŒ–åŠŸèƒ½ä¸å¯ç”¨: {e}")
    
    from job_offers_classifier.job_offers_classfier_old import (
        ChineseTransformerJobOffersClassifier,
        get_recommended_chinese_models
    )
    from job_offers_classifier.job_offers_utils_old import create_hierarchy_node
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import classification_report, accuracy_score
    
    from chinese_job_data_augmentation import EnhancedJobDataProcessor


class HierarchicalEnhancedClassifier(ChineseTransformerJobOffersClassifier):
    """
    åœ¨ç°æœ‰åˆ†ç±»å™¨åŸºç¡€ä¸Šæ·»åŠ å±‚æ¬¡åŒ–åŠŸèƒ½çš„åŒ…è£…ç±»
    """
    
    def __init__(self,
                 model_dir=None,
                 hierarchy=None,
                 ckpt_path=None,
                 transformer_model="hfl/chinese-roberta-wwm-ext",
                 transformer_ckpt_path="",
                 modeling_mode='bottom-up',
                 adam_epsilon=1e-8,
                 learning_rate=2e-5,
                 weight_decay=0.01,
                 max_epochs=20,
                 batch_size=64,
                 max_sequence_length=256,
                 early_stopping=True,
                 early_stopping_delta=0.001,
                 early_stopping_patience=3,
                 devices=1,
                 accelerator="auto",
                 num_nodes=1,
                 threads=-1,
                 precision=16,
                 verbose=True,
                 # æ–°å¢å±‚æ¬¡åŒ–å‚æ•°
                 use_hierarchical_loss=True,
                 use_multitask_learning=False,
                 hierarchical_loss_weights=None,
                 task_weights=None):
        
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(
            model_dir=model_dir,
            hierarchy=hierarchy,
            ckpt_path=ckpt_path,
            transformer_model=transformer_model,
            transformer_ckpt_path=transformer_ckpt_path,
            modeling_mode=modeling_mode,
            adam_epsilon=adam_epsilon,
            learning_rate=learning_rate,
            weight_decay=weight_decay,
            max_epochs=max_epochs,
            batch_size=batch_size,
            max_sequence_length=max_sequence_length,
            early_stopping=early_stopping,
            early_stopping_delta=early_stopping_delta,
            early_stopping_patience=early_stopping_patience,
            devices=devices,
            accelerator=accelerator,
            num_nodes=num_nodes,
            threads=threads,
            precision=precision,
            verbose=verbose
        )
        
        # å±‚æ¬¡åŒ–åŠŸèƒ½é…ç½®
        self.hierarchical_available = HIERARCHICAL_AVAILABLE and hierarchy is not None
        self.use_hierarchical_loss = use_hierarchical_loss and self.hierarchical_available
        self.use_multitask_learning = use_multitask_learning and self.hierarchical_available
        
        # é»˜è®¤æƒé‡é…ç½®
        self.hierarchical_loss_weights = hierarchical_loss_weights or {1: 1, 2:1.0, 3: 1, 4:1}
        self.task_weights = task_weights or {1: 0.1, 2: 0.2, 3: 0.3, 4: 0.4}
        
        if self.verbose and self.hierarchical_available:
            print(f"ğŸ”§ å±‚æ¬¡åŒ–å¢å¼ºåˆ†ç±»å™¨åˆå§‹åŒ–")
            print(f"   å±‚æ¬¡åŒ–æŸå¤±: {'âœ“' if self.use_hierarchical_loss else 'âœ—'}")
            print(f"   å¤šä»»åŠ¡å­¦ä¹ : {'âœ“' if self.use_multitask_learning else 'âœ—'}")
            if self.use_hierarchical_loss:
                print(f"   å±‚æ¬¡æƒé‡: {self.hierarchical_loss_weights}")

    def get_hierarchical_performance(self, X, y_true_codes):
        """è·å–å±‚æ¬¡åŒ–æ€§èƒ½è¯„ä¼°"""
        if not self.use_hierarchical_loss:
            return None
            
        # é¢„æµ‹
        predictions_df = self.predict(X, format='dataframe', top_k=5)
        y_pred_codes = predictions_df['class_1'].tolist()
        
        # è®¡ç®—å„çº§åˆ«å‡†ç¡®ç‡
        level_accuracies = {}
        
        for level in [1, 2, 3, 4]:
            true_level_codes = [code[:level] for code in y_true_codes]
            pred_level_codes = [code[:level] for code in y_pred_codes]
            
            level_acc = accuracy_score(true_level_codes, pred_level_codes)
            level_accuracies[f'level_{level}_accuracy'] = level_acc
        
        return {
            'level_accuracies': level_accuracies,
            'predictions': predictions_df,
            'hierarchical_error_analysis': self._analyze_hierarchical_errors(y_true_codes, y_pred_codes)
        }

    def _analyze_hierarchical_errors(self, y_true_codes, y_pred_codes):
        """åˆ†æå±‚æ¬¡åŒ–é”™è¯¯"""
        error_analysis = {
            'same_1_level': 0,  # 1çº§ç›¸åŒä½†æ›´ç»†çº§åˆ«é”™è¯¯
            'same_2_level': 0,  # 2çº§ç›¸åŒä½†æ›´ç»†çº§åˆ«é”™è¯¯  
            'same_3_level': 0,  # 3çº§ç›¸åŒä½†4çº§é”™è¯¯
            'different_1_level': 0,  # 1çº§å°±ä¸åŒï¼ˆæœ€ä¸¥é‡é”™è¯¯ï¼‰
            'total_errors': 0
        }
        
        for true_code, pred_code in zip(y_true_codes, y_pred_codes):
            if true_code != pred_code:
                error_analysis['total_errors'] += 1
                
                if true_code[:1] != pred_code[:1]:
                    error_analysis['different_1_level'] += 1
                elif true_code[:2] != pred_code[:2]:
                    error_analysis['same_1_level'] += 1
                elif true_code[:3] != pred_code[:3]:
                    error_analysis['same_2_level'] += 1
                else:
                    error_analysis['same_3_level'] += 1
        
        return error_analysis


class HierarchicalExperimentRunner:
    """å±‚æ¬¡åŒ–å®éªŒè¿è¡Œå™¨ - é›†æˆä¸­æ–‡é¢„å¤„ç†"""
    
    def __init__(self, csv_path: str, max_samples: int = 8000):
        self.csv_path = csv_path
        self.max_samples = max_samples
        self._data_cache = {}
        # æµ‹è¯•é…ç½®
        # é€‰é¡¹Aï¼šå¿«é€Ÿæµ‹è¯•ï¼ˆæ¨èï¼‰
        self.test_models = [
            'hfl/chinese-roberta-wwm-ext'  # åªæµ‹è¯•æœ€å¥½çš„æ¨¡å‹
        ]
        
        # é€‰é¡¹Bï¼šå®Œæ•´æµ‹è¯•
        # self.test_models = [
        #     'bert-base-chinese',
        #     'hfl/chinese-bert-wwm-ext',
        #     'hfl/chinese-roberta-wwm-ext'
        # ]
        
      
        self.training_config = {
            'max_epochs': 3,
            'patience': 2,
            'max_seq_length': 256,
            'batch_size': 64,
            'learning_rate': 2e-5
        }
        
        print("ğŸ”¬ å±‚æ¬¡åŒ–å¢å¼ºå®éªŒåˆå§‹åŒ–")
        print(f"   å±‚æ¬¡åŒ–åŠŸèƒ½: {'âœ“' if HIERARCHICAL_AVAILABLE else 'âœ—'}")
        print(f"   ä¸­æ–‡é¢„å¤„ç†: âœ“")

    def load_enhanced_data(self, enable_augmentation=True, target_samples_per_class=6):
        """åŠ è½½å¢å¼ºç‰ˆä¸­æ–‡é¢„å¤„ç†æ•°æ® - å¸¦ç¼“å­˜ä¼˜åŒ–"""
        
        # ğŸš€ æ£€æŸ¥ç¼“å­˜
        cache_key = f"aug_{enable_augmentation}_samples_{target_samples_per_class}_max_{self.max_samples}"
        if cache_key in self._data_cache:
            print(f"âœ… ä½¿ç”¨ç¼“å­˜çš„é¢„å¤„ç†æ•°æ®: {cache_key}")
            return self._data_cache[cache_key]
        
        # åŸæœ‰çš„æ•°æ®å¤„ç†é€»è¾‘...
        data_type = "å¢å¼ºé¢„å¤„ç†" if enable_augmentation else "åŸºç¡€é¢„å¤„ç†"
        print(f"\nğŸ“Š åŠ è½½{data_type}æ•°æ®...")
        
        if enable_augmentation:
            processor = EnhancedJobDataProcessor()
            texts, labels, processing_stats = processor.process_csv_data(
                csv_path=self.csv_path,
                enable_augmentation=True,
                balance_data=True,
                target_samples_per_class=target_samples_per_class
            )
        else:
            processor = EnhancedJobDataProcessor()
            texts, labels, processing_stats = processor.process_csv_data(
                csv_path=self.csv_path,
                enable_augmentation=False,
                balance_data=False,
                target_samples_per_class=1
            )
        
        # é™åˆ¶æ ·æœ¬æ•°ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if self.max_samples and len(texts) > self.max_samples:
            print(f"   é‡‡æ · {self.max_samples} è¡Œä» {len(texts)} è¡Œ")
            indices = np.random.choice(len(texts), size=self.max_samples, replace=False)
            texts = [texts[i] for i in indices]
            labels = [labels[i] for i in indices]
        
        stats = processing_stats['final_stats']
        result = (texts, labels, stats)
        
        # ğŸš€ ç¼“å­˜ç»“æœ
        self._data_cache[cache_key] = result
        print(f"âœ… æ•°æ®å·²ç¼“å­˜: {cache_key}")
        
        return result

    def safe_train_test_split_with_hierarchy(self, texts, labels):
        """è€ƒè™‘ISCOå±‚æ¬¡ç»“æ„çš„å®‰å…¨æ•°æ®åˆ’åˆ†"""
        print("   ğŸ“Š æ™ºèƒ½æ•°æ®åˆ’åˆ†ä¸­...")
        
        # åˆ†æç±»åˆ«åˆ†å¸ƒ
        label_counts = Counter(labels)
        single_sample_classes = [label for label, count in label_counts.items() if count == 1]
        multi_sample_classes = [label for label, count in label_counts.items() if count > 1]
        
        print(f"   4çº§ç¼–ç  - å•æ ·æœ¬ç±»åˆ«: {len(single_sample_classes)}, å¤šæ ·æœ¬ç±»åˆ«: {len(multi_sample_classes)}")
        
        # åˆ†æå„çº§åˆ«åˆ†å¸ƒ
        for level in [1, 2, 3]:
            level_codes = [label[:level] for label in labels]
            level_counts = Counter(level_codes)
            level_single = sum(1 for count in level_counts.values() if count == 1)
            print(f"   {level}çº§ç¼–ç  - å•æ ·æœ¬ç±»åˆ«: {level_single}/{len(level_counts)}")
        
        train_indices = []
        test_indices = []
        
        # å•æ ·æœ¬ç±»åˆ«å…¨éƒ¨æ”¾å…¥è®­ç»ƒé›†
        for i, (text, label) in enumerate(zip(texts, labels)):
            if label in single_sample_classes:
                train_indices.append(i)
        
        # å¤šæ ·æœ¬ç±»åˆ«æ­£å¸¸åˆ†å±‚åˆ’åˆ†
        if multi_sample_classes:
            multi_texts = []
            multi_labels = []
            multi_indices = []
            
            for i, (text, label) in enumerate(zip(texts, labels)):
                if label in multi_sample_classes:
                    multi_texts.append(text)
                    multi_labels.append(label)
                    multi_indices.append(i)
            
            if len(multi_texts) > 0:
                try:
                    # å°è¯•åˆ†å±‚åˆ’åˆ†
                    multi_train_idx, multi_test_idx = train_test_split(
                        range(len(multi_texts)), 
                        test_size=0.2, 
                        random_state=42, 
                        stratify=multi_labels
                    )
                    print(f"   âœ“ æˆåŠŸè¿›è¡Œåˆ†å±‚åˆ’åˆ†")
                except ValueError as e:
                    print(f"   âš ï¸ åˆ†å±‚åˆ’åˆ†å¤±è´¥ï¼Œä½¿ç”¨éšæœºåˆ’åˆ†: {e}")
                    # åˆ†å±‚å¤±è´¥ï¼Œä½¿ç”¨éšæœºåˆ’åˆ†
                    multi_train_idx, multi_test_idx = train_test_split(
                        range(len(multi_texts)), 
                        test_size=0.2, 
                        random_state=42
                    )
                
                train_indices.extend([multi_indices[i] for i in multi_train_idx])
                test_indices.extend([multi_indices[i] for i in multi_test_idx])
        
        # æ„å»ºæœ€ç»ˆçš„è®­ç»ƒæµ‹è¯•é›†
        train_texts = [texts[i] for i in train_indices]
        train_labels = [labels[i] for i in train_indices]
        test_texts = [texts[i] for i in test_indices]
        test_labels = [labels[i] for i in test_indices]
        
        # éªŒè¯æµ‹è¯•é›†
        if len(test_texts) == 0 and len(train_texts) >= 10:
            print(f"   âš ï¸ æµ‹è¯•é›†ä¸ºç©ºï¼Œä»è®­ç»ƒé›†ä¸­åˆ†å‡ºä¸€éƒ¨åˆ†")
            split_point = max(1, len(train_texts) // 5)
            test_texts = train_texts[-split_point:]
            test_labels = train_labels[-split_point:]
            train_texts = train_texts[:-split_point]
            train_labels = train_labels[:-split_point]
        
        print(f"   âœ“ æœ€ç»ˆåˆ’åˆ† - è®­ç»ƒ: {len(train_texts)}, æµ‹è¯•: {len(test_texts)}")
        
        # æœ€ç»ˆéªŒè¯ï¼šç¡®ä¿æµ‹è¯•é›†ä¸­æ²¡æœ‰å•æ ·æœ¬ç±»åˆ«
        if len(test_texts) > 0:
            test_label_counts = Counter(test_labels)
            test_single_classes = [label for label, count in test_label_counts.items() if count == 1]
            if test_single_classes:
                print(f"   âš ï¸ æµ‹è¯•é›†ä¸­ä»æœ‰ {len(test_single_classes)} ä¸ªå•æ ·æœ¬ç±»åˆ«")
        
        return train_texts, test_texts, train_labels, test_labels

    def run_hierarchical_comparison(self):
        """è¿è¡Œå±‚æ¬¡åŒ–åŠŸèƒ½å¯¹æ¯”å®éªŒ - ä¼˜åŒ–ç‰ˆ"""
        print("ğŸ”¬ å¼€å§‹ä¼˜åŒ–ç‰ˆå±‚æ¬¡åŒ–åŠŸèƒ½å¯¹æ¯”å®éªŒ")
        print("ğŸš€ ä¼˜åŒ–é¡¹ï¼šå¢å¤§batch_size, å‡å°‘epoch, æ¿€è¿›æ—©åœ, æ•°æ®ç¼“å­˜")
        print("=" * 80)
        
        results_dir = Path("hierarchical_comparison_results_optimized")
        results_dir.mkdir(exist_ok=True)
        
        all_results = []
        
        # ğŸš€ å…ˆåªæµ‹è¯•å¢å¼ºé¢„å¤„ç†ï¼ˆé€šå¸¸æ•ˆæœæ›´å¥½ï¼‰
        data_configs = [
            {"enable_augmentation": True, "name": "å¢å¼ºé¢„å¤„ç†", "target_samples": 6}
            # å¦‚æœå¢å¼ºé¢„å¤„ç†æ•ˆæœå¥½ï¼Œå†æµ‹è¯•åŸºç¡€é¢„å¤„ç†
        ]
        
        for data_config in data_configs:
            print(f"\n{'='*80}")
            print(f"ğŸ“Š æ•°æ®å¤„ç†æ–¹å¼: {data_config['name']}")
            print(f"{'='*80}")
            
            # ğŸš€ é¢„åŠ è½½å¹¶ç¼“å­˜æ•°æ®
            texts, labels, stats = self.load_enhanced_data(
                enable_augmentation=data_config["enable_augmentation"],
                target_samples_per_class=data_config["target_samples"]
            )
            
            # å¯¹æ¯ä¸ªæ¨¡å‹è¿è¡Œå¯¹æ¯”å®éªŒ
            for model_name in self.test_models:
                print(f"\n{'='*60}")
                print(f"ğŸ¤– æµ‹è¯•æ¨¡å‹: {model_name}")
                print(f"{'='*60}")
                
                # å®éªŒ1: æ ‡å‡†æŸå¤±å‡½æ•°
                standard_result = self._run_single_experiment(
                    model_name, texts, labels, 
                    f"Standard Loss ({data_config['name']})", 
                    results_dir,
                    use_hierarchical_loss=False
                )
                all_results.append(standard_result)
                
                # å®éªŒ2: å±‚æ¬¡åŒ–æŸå¤±å‡½æ•°
                if HIERARCHICAL_AVAILABLE:
                    hierarchical_result = self._run_single_experiment(
                        model_name, texts, labels, 
                        f"Hierarchical Loss ({data_config['name']})", 
                        results_dir,
                        use_hierarchical_loss=True
                    )
                    all_results.append(hierarchical_result)
                    
                    # æ‰“å°å¯¹æ¯”ç»“æœ
                    if standard_result['status'] == 'success' and hierarchical_result['status'] == 'success':
                        self._print_comparison(standard_result, hierarchical_result, model_name, data_config['name'])
                else:
                    print("âš ï¸ å±‚æ¬¡åŒ–åŠŸèƒ½ä¸å¯ç”¨,è·³è¿‡å±‚æ¬¡åŒ–æŸå¤±å®éªŒ")
        
        # ç”ŸæˆæŠ¥å‘Š
        self._generate_hierarchical_report(all_results, results_dir)
        
        return all_results, results_dir


    def _run_single_experiment(self, model_name, texts, labels, experiment_name, results_dir, 
                            use_hierarchical_loss=False):
        """è¿è¡Œå•ä¸ªå®éªŒ"""
        print(f"\nğŸ¯ {experiment_name} - {model_name}")
        
        try:
            # ä½¿ç”¨æ™ºèƒ½æ•°æ®åˆ†å‰²
            train_texts, test_texts, train_labels, test_labels = self.safe_train_test_split_with_hierarchy(texts, labels)
            
            if len(test_texts) < 5:
                print(f"   âŒ æµ‹è¯•é›†æ ·æœ¬ä¸è¶³: {len(test_texts)}")
                return {
                    'model_name': model_name,
                    'experiment_name': experiment_name,
                    'use_hierarchical_loss': use_hierarchical_loss,
                    'status': 'failed',
                    'error': f'Insufficient test data: {len(test_texts)} samples'
                }
            
            # â­ æ·»åŠ éªŒè¯é›†åˆ’åˆ†
            val_size = min(200, len(test_texts) // 2)  # ä»æµ‹è¯•é›†ä¸­åˆ†å‡ºä¸€éƒ¨åˆ†ä½œä¸ºéªŒè¯é›†
            if val_size > 0 and len(test_texts) > val_size:
                val_texts = test_texts[:val_size]
                val_labels = test_labels[:val_size]
                final_test_texts = test_texts[val_size:]
                final_test_labels = test_labels[val_size:]
            else:
                val_texts, val_labels = None, None
                final_test_texts = test_texts
                final_test_labels = test_labels
            
            # åˆ›å»ºå±‚æ¬¡ç»“æ„
            hierarchy = self.create_isco_hierarchy_from_codes(set(labels))
            
            # æ¨¡å‹ç›®å½•
            safe_model_name = model_name.replace('/', '_').replace('-', '_')
            safe_exp_name = experiment_name.lower().replace(' ', '_').replace('(', '').replace(')', '')
            model_dir = results_dir / f"model_{safe_model_name}_{safe_exp_name}"
            
            start_time = time.time()
            
            # åˆ›å»ºåˆ†ç±»å™¨
            if use_hierarchical_loss and HIERARCHICAL_AVAILABLE:
                classifier = ChineseTransformerJobOffersClassifier(
                    model_dir=str(model_dir),
                    hierarchy=hierarchy,
                    transformer_model=model_name,
                    learning_rate=self.training_config['learning_rate'],
                    batch_size=self.training_config['batch_size'],
                    max_epochs=self.training_config['max_epochs'],
                    early_stopping=True,
                    early_stopping_patience=self.training_config['patience'],
                    max_sequence_length=self.training_config['max_seq_length'],
                    devices=1,
                    accelerator="gpu" if torch.cuda.is_available() else "cpu",
                    precision="16-mixed" if torch.cuda.is_available() else 32,
                    threads=0,
                    verbose=True,
                    # â­ æ˜¾å¼ä¼ é€’å±‚æ¬¡åŒ–å‚æ•°
                    use_hierarchical_loss=True,
                    hierarchical_loss_weights={1: 6, 2: 0.01, 3: 0.01, 4: 0.01}
                )
                print(f"   âœ“ åˆ›å»ºå±‚æ¬¡åŒ–å¢å¼ºåˆ†ç±»å™¨")
            else:
                classifier = ChineseTransformerJobOffersClassifier(
                    model_dir=str(model_dir),
                    hierarchy=hierarchy,
                    transformer_model=model_name,
                    learning_rate=self.training_config['learning_rate'],
                    batch_size=self.training_config['batch_size'],
                    max_epochs=self.training_config['max_epochs'],
                    early_stopping=True,
                    early_stopping_patience=self.training_config['patience'],
                    max_sequence_length=self.training_config['max_seq_length'],
                    devices=1,
                    accelerator="gpu" if torch.cuda.is_available() else "cpu",
                    precision="16-mixed" if torch.cuda.is_available() else 32,
                    threads=0,
                    verbose=True,
                    # â­ æ˜¾å¼ä¼ é€’å±‚æ¬¡åŒ–å‚æ•°ï¼ˆå…³é—­ï¼‰
                    use_hierarchical_loss=False,
                    use_multitask_learning=False
                )
                print(f"   âœ“ åˆ›å»ºæ ‡å‡†åˆ†ç±»å™¨")
            
            print(f"   è®­ç»ƒæ ·æœ¬: {len(train_texts)}")
            print(f"   éªŒè¯æ ·æœ¬: {len(val_texts) if val_texts else 0}")
            print(f"   æµ‹è¯•æ ·æœ¬: {len(final_test_texts)}")
            
            # è®­ç»ƒï¼ˆåŒ…å«éªŒè¯é›†ï¼‰
            print(f"   ğŸ¯ å¼€å§‹è®­ç»ƒ...")
            if val_texts and val_labels:
                classifier.fit(train_labels, train_texts, y_val=val_labels, X_val=val_texts)
            else:
                classifier.fit(train_labels, train_texts)
            
            # é¢„æµ‹å’Œè¯„ä¼°
            print(f"   ğŸ”® é¢„æµ‹è¯„ä¼°ä¸­...")
            predictions_df = classifier.predict(final_test_texts, format='dataframe', top_k=5)
            
            # å…¶ä½™ä»£ç ä¿æŒä¸å˜...
                
           # â­ ä¿®å¤ï¼šç¡®ä¿é¢„æµ‹ç»“æœå’Œæ ‡ç­¾æ•°é‡ä¸€è‡´
            if len(predictions_df) != len(final_test_labels):
                print(f"   âš ï¸ é¢„æµ‹ç»“æœæ•°é‡ä¸åŒ¹é…: é¢„æµ‹{len(predictions_df)}, æ ‡ç­¾{len(final_test_labels)}")
                min_len = min(len(predictions_df), len(final_test_labels))
                predictions_df = predictions_df.iloc[:min_len]
                final_test_labels = final_test_labels[:min_len]
                print(f"   ğŸ“ è°ƒæ•´åæ•°é‡: {min_len}")

            # åŸºç¡€æŒ‡æ ‡
            y_true = final_test_labels
            y_pred = predictions_df['class_1'].tolist()

            # ğŸŒŸ æ–°å¢ï¼šè®¡ç®—å±‚æ¬¡åŒ–å‡†ç¡®ç‡ï¼ˆ1-4çº§ï¼‰
            hierarchical_accuracies = {}
            for level in [1, 2, 3, 4]:
                # æˆªå–åˆ°å¯¹åº”çº§åˆ«
                y_true_level = [str(code)[:level] for code in y_true]
                y_pred_level = [str(code)[:level] for code in y_pred]
                
                level_accuracy = accuracy_score(y_true_level, y_pred_level)
                hierarchical_accuracies[f'level_{level}_accuracy'] = level_accuracy
            
            # åŸæœ‰çš„4çº§å‡†ç¡®ç‡
            accuracy_4_level = hierarchical_accuracies['level_4_accuracy']
            
            # ğŸŒŸ æ–°å¢ï¼šè®¡ç®—å±‚æ¬¡åŒ–Top-kå‡†ç¡®ç‡
            hierarchical_top_k = {}
            for k in [3, 5]:
                level_top_k = {}
                for level in [1, 2, 3, 4]:
                    level_correct = 0
                    for i, true_label in enumerate(y_true):
                        true_level_code = str(true_label)[:level]
                        # æ£€æŸ¥top-ké¢„æµ‹ä¸­æ˜¯å¦æœ‰åŒ¹é…çš„çº§åˆ«
                        for j in range(1, k+1):
                            if f'class_{j}' in predictions_df.columns:
                                pred_code = str(predictions_df.iloc[i][f'class_{j}'])[:level]
                                if true_level_code == pred_code:
                                    level_correct += 1
                                    break
                    level_top_k[f'level_{level}'] = level_correct / len(y_true)
                hierarchical_top_k[f'top_{k}'] = level_top_k
            
            # ğŸŒŸ æ–°å¢ï¼šå±‚æ¬¡åŒ–é”™è¯¯åˆ†æï¼ˆå¸¦å¼‚å¸¸å¤„ç†ï¼‰
            try:
                hierarchical_error_analysis = self._analyze_hierarchical_errors_detailed(y_true, y_pred)
            except Exception as e:
                print(f"   âš ï¸ å±‚æ¬¡åŒ–é”™è¯¯åˆ†æå¤±è´¥: {e}")
                hierarchical_error_analysis = {
                    'total_samples': len(y_true),
                    'error': str(e)
                }
            
            # è®¡ç®—ä¼ ç»ŸTop-kå‡†ç¡®ç‡ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
            top_3_acc = sum(
                true_label in [predictions_df.iloc[i][f'class_{j}'] for j in range(1, 4)]
                for i, true_label in enumerate(y_true)
            ) / len(y_true)
            
            top_5_acc = sum(
                true_label in [predictions_df.iloc[i][f'class_{j}'] for j in range(1, 6)]
                for i, true_label in enumerate(y_true)
            ) / len(y_true)
            
            training_time = time.time() - start_time
            
            result = {
                'model_name': model_name,
                'experiment_name': experiment_name,
                'use_hierarchical_loss': use_hierarchical_loss,
                'train_samples': len(train_texts),
                'test_samples': len(final_test_texts),
                
                # ğŸŒŸ å±‚æ¬¡åŒ–å‡†ç¡®ç‡ï¼ˆæ ¸å¿ƒæŒ‡æ ‡ï¼‰
                'level_1_accuracy': hierarchical_accuracies['level_1_accuracy'],
                'level_2_accuracy': hierarchical_accuracies['level_2_accuracy'], 
                'level_3_accuracy': hierarchical_accuracies['level_3_accuracy'],
                'level_4_accuracy': hierarchical_accuracies['level_4_accuracy'],
                
                # ä¼ ç»ŸæŒ‡æ ‡ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
                'accuracy': accuracy_4_level,  # ç­‰åŒäºlevel_4_accuracy
                'top_3_accuracy': top_3_acc,
                'top_5_accuracy': top_5_acc,
                
                # ğŸŒŸ å±‚æ¬¡åŒ–Top-kå‡†ç¡®ç‡
                'hierarchical_top_3': hierarchical_top_k['top_3'],
                'hierarchical_top_5': hierarchical_top_k['top_5'],
                
                # ğŸŒŸ å±‚æ¬¡åŒ–é”™è¯¯åˆ†æ
                'hierarchical_error_analysis': hierarchical_error_analysis,
                
                'training_time_minutes': training_time / 60,
                'status': 'success'
            }
            
            print(f"âœ… {experiment_name} å®Œæˆ!")
            print(f"\nğŸ¯ å±‚æ¬¡åŒ–å‡†ç¡®ç‡è¯„ä¼°:")
            print(f"   1çº§å‡†ç¡®ç‡: {hierarchical_accuracies['level_1_accuracy']:.4f} ({hierarchical_accuracies['level_1_accuracy']*100:.2f}%)")
            print(f"   2çº§å‡†ç¡®ç‡: {hierarchical_accuracies['level_2_accuracy']:.4f} ({hierarchical_accuracies['level_2_accuracy']*100:.2f}%)")
            print(f"   3çº§å‡†ç¡®ç‡: {hierarchical_accuracies['level_3_accuracy']:.4f} ({hierarchical_accuracies['level_3_accuracy']*100:.2f}%)")
            print(f"   4çº§å‡†ç¡®ç‡: {hierarchical_accuracies['level_4_accuracy']:.4f} ({hierarchical_accuracies['level_4_accuracy']*100:.2f}%)")
            
            print(f"\nğŸ“Š ä¼ ç»ŸTop-kå‡†ç¡®ç‡:")
            print(f"   Top-3å‡†ç¡®ç‡: {top_3_acc:.4f} ({top_3_acc*100:.2f}%)")
            print(f"   Top-5å‡†ç¡®ç‡: {top_5_acc:.4f} ({top_5_acc*100:.2f}%)")
            
            print(f"\nğŸŒŸ å±‚æ¬¡åŒ–Top-3å‡†ç¡®ç‡:")
            for level in [1, 2, 3, 4]:
                acc = hierarchical_top_k['top_3'][f'level_{level}']
                print(f"   {level}çº§Top-3: {acc:.4f} ({acc*100:.2f}%)")
            
            print(f"\nâ±ï¸ è®­ç»ƒæ—¶é—´: {training_time/60:.1f} åˆ†é’Ÿ")
            
            # ğŸŒŸ æ˜¾ç¤ºå±‚æ¬¡åŒ–é”™è¯¯åˆ†æï¼ˆå¸¦å¼‚å¸¸å¤„ç†ï¼‰
            if 'error' not in hierarchical_error_analysis:
                self._print_hierarchical_error_analysis(hierarchical_error_analysis)
            
            return result
            
        except Exception as e:
            print(f"âŒ {experiment_name} å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
            return {
                'model_name': model_name,
                'experiment_name': experiment_name,
                'use_hierarchical_loss': use_hierarchical_loss,
                'status': 'failed',
                'error': str(e)
            }
    def _analyze_hierarchical_errors_detailed(self, y_true_codes, y_pred_codes):
        """è¯¦ç»†çš„å±‚æ¬¡åŒ–é”™è¯¯åˆ†æ - ä¿®å¤ç‰ˆ"""
        error_analysis = {
            'total_samples': len(y_true_codes),
            'correct_samples': 0,
            'error_distribution': {
                'level_1_errors': 0,  # 1çº§å°±é”™è¯¯ï¼ˆæœ€ä¸¥é‡ï¼‰
                'level_2_errors': 0,  # 1çº§å¯¹ï¼Œ2çº§é”™è¯¯
                'level_3_errors': 0,  # 1-2çº§å¯¹ï¼Œ3çº§é”™è¯¯
                'level_4_errors': 0,  # 1-3çº§å¯¹ï¼Œ4çº§é”™è¯¯
            },
            'level_agreements': {
                'level_1_agreement': 0,  # 1çº§ç›¸åŒçš„æ ·æœ¬æ•°
                'level_2_agreement': 0,  # 1-2çº§ç›¸åŒçš„æ ·æœ¬æ•°
                'level_3_agreement': 0,  # 1-3çº§ç›¸åŒçš„æ ·æœ¬æ•°
                'level_4_agreement': 0,  # å®Œå…¨ç›¸åŒçš„æ ·æœ¬æ•°
            }
        }
        
        for true_code, pred_code in zip(y_true_codes, y_pred_codes):
            true_str = str(true_code)
            pred_str = str(pred_code)
            
            # æ£€æŸ¥å„çº§åˆ«çš„ä¸€è‡´æ€§
            level_matches = []
            for level in [1, 2, 3, 4]:
                true_level = true_str[:level]
                pred_level = pred_str[:level]
                level_matches.append(true_level == pred_level)
            
            # ç»Ÿè®¡å„çº§åˆ«åŒæ„åº¦
            if level_matches[0]:  # 1çº§ç›¸åŒ
                error_analysis['level_agreements']['level_1_agreement'] += 1
            if all(level_matches[:2]):  # 1-2çº§ç›¸åŒ
                error_analysis['level_agreements']['level_2_agreement'] += 1
            if all(level_matches[:3]):  # 1-3çº§ç›¸åŒ
                error_analysis['level_agreements']['level_3_agreement'] += 1
            if all(level_matches):  # å®Œå…¨ç›¸åŒ
                error_analysis['level_agreements']['level_4_agreement'] += 1
                error_analysis['correct_samples'] += 1
            else:
                # åˆ†æé”™è¯¯ç±»å‹
                if not level_matches[0]:
                    error_analysis['error_distribution']['level_1_errors'] += 1
                elif not level_matches[1]:
                    error_analysis['error_distribution']['level_2_errors'] += 1
                elif not level_matches[2]:
                    error_analysis['error_distribution']['level_3_errors'] += 1
                else:
                    error_analysis['error_distribution']['level_4_errors'] += 1
        
        # ğŸ”§ ä¿®å¤ï¼šåˆ†åˆ«è®¡ç®—æ¯”ä¾‹ï¼Œé¿å…å­—å…¸è¿­ä»£æ—¶ä¿®æ”¹
        total = error_analysis['total_samples']
        
        # å…ˆæ”¶é›†éœ€è¦æ·»åŠ çš„é”®å€¼å¯¹
        agreement_rates = {}
        for key in list(error_analysis['level_agreements'].keys()):  # ä½¿ç”¨list()åˆ›å»ºå‰¯æœ¬
            rate_key = key + '_rate'
            agreement_rates[rate_key] = error_analysis['level_agreements'][key] / total
        
        error_rates = {}
        for key in list(error_analysis['error_distribution'].keys()):  # ä½¿ç”¨list()åˆ›å»ºå‰¯æœ¬
            rate_key = key + '_rate'
            error_rates[rate_key] = error_analysis['error_distribution'][key] / total
        
        # ç„¶åä¸€æ¬¡æ€§æ·»åŠ æ‰€æœ‰æ–°é”®
        error_analysis['level_agreements'].update(agreement_rates)
        error_analysis['error_distribution'].update(error_rates)
        
        return error_analysis


    def _print_hierarchical_error_analysis(self, error_analysis):
        """æ‰“å°å±‚æ¬¡åŒ–é”™è¯¯åˆ†æ"""
        print(f"\nğŸ” å±‚æ¬¡åŒ–é”™è¯¯åˆ†æ:")
        print(f"   æ€»æ ·æœ¬æ•°: {error_analysis['total_samples']}")
        print(f"   å®Œå…¨æ­£ç¡®: {error_analysis['correct_samples']} ({error_analysis['correct_samples']/error_analysis['total_samples']*100:.1f}%)")
        
        print(f"\nğŸ“Š å„çº§åˆ«åŒæ„åº¦:")
        agreements = error_analysis['level_agreements']
        for level in [1, 2, 3, 4]:
            count = agreements[f'level_{level}_agreement']
            rate = agreements[f'level_{level}_agreement_rate']
            print(f"   {level}çº§åŒæ„: {count} ({rate*100:.1f}%)")
        
        print(f"\nâŒ é”™è¯¯åˆ†å¸ƒ:")
        errors = error_analysis['error_distribution']
        for level in [1, 2, 3, 4]:
            count = errors[f'level_{level}_errors']
            rate = errors[f'level_{level}_errors_rate']
            error_desc = {
                1: "1çº§å°±é”™è¯¯(æœ€ä¸¥é‡)",
                2: "1çº§å¯¹,2çº§é”™",  
                3: "1-2çº§å¯¹,3çº§é”™",
                4: "1-3çº§å¯¹,ä»…4çº§é”™"
            }
            print(f"   {error_desc[level]}: {count} ({rate*100:.1f}%)")
    def _print_comparison(self, standard_result, hierarchical_result, model_name, data_config_name):
        """æ‰“å°å±‚æ¬¡åŒ–å¯¹æ¯”ç»“æœ - é‡ç‚¹å…³æ³¨å„çº§åˆ«æ”¹è¿›"""
        print(f"\nğŸ“Š {model_name} å±‚æ¬¡åŒ–å¯¹æ¯”ç»“æœ ({data_config_name}):")
        
        # ğŸŒŸ å±‚æ¬¡åŒ–å‡†ç¡®ç‡å¯¹æ¯”ï¼ˆæ ¸å¿ƒï¼‰
        print(f"\nğŸ¯ å„çº§åˆ«å‡†ç¡®ç‡å¯¹æ¯”:")
        for level in [1, 2, 3, 4]:
            std_acc = standard_result[f'level_{level}_accuracy']
            hier_acc = hierarchical_result[f'level_{level}_accuracy']
            improvement = hier_acc - std_acc
            
            print(f"   {level}çº§: {std_acc:.4f} â†’ {hier_acc:.4f} ({improvement:+.4f}, {improvement*100:+.2f}%)")
        
        # ğŸŒŸ å±‚æ¬¡åŒ–ä»·å€¼åˆ†æ
        print(f"\nğŸ’¡ å±‚æ¬¡åŒ–ä»·å€¼åˆ†æ:")
        
        # è®¡ç®—å±‚æ¬¡åŒ–æ”¹è¿›æƒé‡åˆ†æ•°
        level_weights = {1: 4.0, 2: 3.0, 3: 2.0, 4: 1.0}  # ç²—ç²’åº¦æ›´é‡è¦
        weighted_improvement = 0
        for level in [1, 2, 3, 4]:
            std_acc = standard_result[f'level_{level}_accuracy']
            hier_acc = hierarchical_result[f'level_{level}_accuracy']
            improvement = hier_acc - std_acc
            weighted_improvement += improvement * level_weights[level]
        
        print(f"   åŠ æƒæ”¹è¿›åˆ†æ•°: {weighted_improvement:+.4f} (æƒé‡: 1çº§=4.0, 2çº§=3.0, 3çº§=2.0, 4çº§=1.0)")
        
        # ğŸŒŸ é”™è¯¯ä¸¥é‡æ€§åˆ†æ
        if 'hierarchical_error_analysis' in hierarchical_result:
            std_errors = standard_result.get('hierarchical_error_analysis', {}).get('error_distribution', {})
            hier_errors = hierarchical_result['hierarchical_error_analysis']['error_distribution']
            
            print(f"\nğŸ” é”™è¯¯ä¸¥é‡æ€§æ”¹è¿›:")
            error_types = {
                'level_1_errors': '1çº§é”™è¯¯(æœ€ä¸¥é‡)',
                'level_2_errors': '2çº§é”™è¯¯', 
                'level_3_errors': '3çº§é”™è¯¯',
                'level_4_errors': '4çº§é”™è¯¯(æœ€è½»å¾®)'
            }
            
            for error_type, desc in error_types.items():
                std_rate = std_errors.get(f'{error_type}_rate', 0)
                hier_rate = hier_errors.get(f'{error_type}_rate', 0)
                reduction = std_rate - hier_rate
                print(f"   {desc}: {std_rate:.3f} â†’ {hier_rate:.3f} ({reduction:+.3f})")
        
        # ä¼ ç»ŸæŒ‡æ ‡å¯¹æ¯”
        std_acc_4 = standard_result['accuracy']
        hier_acc_4 = hierarchical_result['accuracy']
        improvement_4 = hier_acc_4 - std_acc_4
        
        print(f"\nğŸ“ˆ ä¼ ç»ŸæŒ‡æ ‡å¯¹æ¯”:")
        print(f"   4çº§å‡†ç¡®ç‡: {std_acc_4:.4f} â†’ {hier_acc_4:.4f} ({improvement_4:+.4f}, {improvement_4*100:+.2f}%)")
        print(f"   Top-3: {standard_result['top_3_accuracy']:.4f} â†’ {hierarchical_result['top_3_accuracy']:.4f}")
        print(f"   Top-5: {standard_result['top_5_accuracy']:.4f} â†’ {hierarchical_result['top_5_accuracy']:.4f}")
        
        # ğŸŒŸ å±‚æ¬¡åŒ–æ•ˆæœè¯„åˆ¤
        print(f"\nğŸ‰ å±‚æ¬¡åŒ–æ•ˆæœè¯„åˆ¤:")
        if weighted_improvement > 0.02:
            print(f"   âœ… å±‚æ¬¡åŒ–æŸå¤±æ˜¾è‘—æ”¹å–„åˆ†ç±»è´¨é‡!")
        elif weighted_improvement > 0.01:
            print(f"   âœ“ å±‚æ¬¡åŒ–æŸå¤±æ˜æ˜¾æ”¹å–„åˆ†ç±»è´¨é‡")
        elif weighted_improvement > 0:
            print(f"   âš–ï¸ å±‚æ¬¡åŒ–æŸå¤±è½»å¾®æ”¹å–„åˆ†ç±»è´¨é‡")
        else:
            print(f"   âš ï¸ å±‚æ¬¡åŒ–æŸå¤±éœ€è¦è¿›ä¸€æ­¥è°ƒä¼˜")
        
        # å…·ä½“å»ºè®®
        level_1_improvement = hierarchical_result['level_1_accuracy'] - standard_result['level_1_accuracy']
        level_4_improvement = hierarchical_result['level_4_accuracy'] - standard_result['level_4_accuracy']
        
        if level_1_improvement > 0.01 and level_4_improvement < 0:
            print(f"   ğŸ’¡ æˆåŠŸå®ç°\"ç‰ºç‰²ç»†èŠ‚æ¢å–åŸºç¡€å‡†ç¡®æ€§\"çš„ç›®æ ‡")
        elif level_1_improvement > 0 and level_4_improvement >= 0:
            print(f"   ğŸ¯ å®ç°äº†åŒèµ¢ï¼šæ—¢æå‡åŸºç¡€åˆä¿æŒç»†èŠ‚")
        elif level_1_improvement < 0:
            print(f"   âš ï¸ å»ºè®®è°ƒæ•´å±‚æ¬¡æƒé‡ï¼ŒåŠ å¼ºå¯¹ç²—ç²’åº¦åˆ†ç±»çš„é‡è§†")

    def create_isco_hierarchy_from_codes(self, isco_codes):
        """ä»ISCOç¼–ç åˆ›å»ºå±‚æ¬¡ç»“æ„"""
        hierarchy = {}
        
        for code in isco_codes:
            code_str = str(code).zfill(4)
            
            for level in [1, 2, 3, 4]:
                level_code = code_str[:level]
                if level_code not in hierarchy:
                    hierarchy[level_code] = create_hierarchy_node(
                        level_code, 
                        f"ISCO-{level}ä½-{level_code}"
                    )
        
        return hierarchy

# åœ¨ä½ çš„ä»£ç ä¸­æ‰¾åˆ° _generate_hierarchical_report æ–¹æ³•ï¼Œæ›¿æ¢å…¶ä¸­çš„ä¸€éƒ¨åˆ†

    def _generate_hierarchical_report(self, results, results_dir):
        """ç”Ÿæˆå¢å¼ºçš„å±‚æ¬¡åŒ–å®éªŒæŠ¥å‘Š"""
        print(f"\nğŸ“Š ç”Ÿæˆå±‚æ¬¡åŒ–å®éªŒæŠ¥å‘Š...")
        
        # ä¿å­˜åŸå§‹ç»“æœ
        results_df = pd.DataFrame(results)
        results_df.to_csv(results_dir / "hierarchical_comparison_results.csv", index=False)
        
        # åˆ†æç»“æœ
        successful_results = [r for r in results if r['status'] == 'success']
        
        if len(successful_results) == 0:
            print("âŒ æ²¡æœ‰æˆåŠŸçš„å®éªŒç»“æœ")
            return
        
        # ğŸŒŸ å±‚æ¬¡åŒ–æ”¹è¿›åˆ†æ
        hierarchical_improvements = []
        
        for model_name in self.test_models:
            model_results = [r for r in successful_results if r['model_name'] == model_name]
            
            for data_type in ['åŸºç¡€é¢„å¤„ç†', 'å¢å¼ºé¢„å¤„ç†']:
                type_results = [r for r in model_results if data_type in r['experiment_name']]
                
                standard = next((r for r in type_results if not r['use_hierarchical_loss']), None)
                hierarchical = next((r for r in type_results if r['use_hierarchical_loss']), None)
                
                if standard and hierarchical:
                    # ğŸŒŸ è®¡ç®—å„çº§åˆ«æ”¹è¿›
                    level_improvements = {}
                    weighted_improvement = 0
                    level_weights = {1: 4.0, 2: 3.0, 3: 2.0, 4: 1.0}
                    
                    for level in [1, 2, 3, 4]:
                        std_acc = standard[f'level_{level}_accuracy']
                        hier_acc = hierarchical[f'level_{level}_accuracy']
                        improvement = hier_acc - std_acc
                        level_improvements[f'level_{level}_improvement'] = improvement
                        weighted_improvement += improvement * level_weights[level]
                    
                    hierarchical_improvements.append({
                        'model_name': model_name,
                        'data_type': data_type,
                        'weighted_improvement': weighted_improvement,
                        **level_improvements,
                        'standard_level_1': standard['level_1_accuracy'],
                        'hierarchical_level_1': hierarchical['level_1_accuracy'],
                        'standard_level_4': standard['level_4_accuracy'], 
                        'hierarchical_level_4': hierarchical['level_4_accuracy'],
                    })
        
        # ğŸŒŸ ç”Ÿæˆå¢å¼ºæŠ¥å‘Š
        report = {
            'experiment_info': {
                'experiment_type': 'Enhanced Hierarchical Loss Comparison',
                'timestamp': datetime.now().isoformat(),
                'focus': 'Multi-level accuracy analysis',
                'evaluation_philosophy': 'Prioritize coarse-grained accuracy over fine-grained',
                'hierarchical_available': HIERARCHICAL_AVAILABLE,
                'models_tested': self.test_models,
            },
            'hierarchical_results': hierarchical_improvements,
            'summary': {
                'avg_weighted_improvement': np.mean([imp['weighted_improvement'] for imp in hierarchical_improvements]) if hierarchical_improvements else 0,
                'avg_level_1_improvement': np.mean([imp['level_1_improvement'] for imp in hierarchical_improvements]) if hierarchical_improvements else 0,
                'avg_level_4_improvement': np.mean([imp['level_4_improvement'] for imp in hierarchical_improvements]) if hierarchical_improvements else 0,
                'best_hierarchical_combo': max(hierarchical_improvements, key=lambda x: x['weighted_improvement']) if hierarchical_improvements else None
            },
            'raw_results': results
        }
        
        with open(results_dir / "enhanced_hierarchical_report.json", 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2, default=str)
        
        # ğŸŒŸ æ‰“å°å¢å¼ºåˆ†æ
        print(f"\nğŸ‰ å¢å¼ºå±‚æ¬¡åŒ–åˆ†æå®Œæˆ!")
        
        if hierarchical_improvements:
            print(f"\nğŸ¯ å±‚æ¬¡åŒ–æŸå¤±å‡½æ•°æ•ˆæœåˆ†æ:")
            
            summary = report['summary']
            print(f"   å¹³å‡åŠ æƒæ”¹è¿›: {summary['avg_weighted_improvement']:+.4f}")
            print(f"   å¹³å‡1çº§æ”¹è¿›: {summary['avg_level_1_improvement']:+.4f} ({summary['avg_level_1_improvement']*100:+.2f}%)")
            print(f"   å¹³å‡4çº§æ”¹è¿›: {summary['avg_level_4_improvement']:+.4f} ({summary['avg_level_4_improvement']*100:+.2f}%)")
            
            # æŒ‰æ¨¡å‹æ˜¾ç¤º
            print(f"\nğŸ”¹ å„æ¨¡å‹è¡¨ç°:")
            for imp in hierarchical_improvements:
                model_short = imp['model_name'].split('/')[-1]
                print(f"   {model_short} ({imp['data_type']}):")
                print(f"     åŠ æƒæ”¹è¿›: {imp['weighted_improvement']:+.4f}")
                print(f"     1çº§: {imp['level_1_improvement']:+.4f}, 4çº§: {imp['level_4_improvement']:+.4f}")
            
            # ğŸŒŸ æ•ˆæœæ€»ç»“
            avg_weighted = summary['avg_weighted_improvement']
            avg_level_1 = summary['avg_level_1_improvement']
            avg_level_4 = summary['avg_level_4_improvement']
            
            print(f"\nğŸ’¡ å±‚æ¬¡åŒ–ä»·å€¼æ€»ç»“:")
            if avg_weighted > 0.02:
                print(f"   ğŸ‰ å±‚æ¬¡åŒ–æŸå¤±æ˜¾è‘—æå‡æ•´ä½“åˆ†ç±»è´¨é‡!")
            elif avg_weighted > 0.01:
                print(f"   âœ… å±‚æ¬¡åŒ–æŸå¤±æ˜æ˜¾æ”¹å–„åˆ†ç±»å±‚æ¬¡æ€§")
            elif avg_weighted > 0:
                print(f"   âš–ï¸ å±‚æ¬¡åŒ–æŸå¤±æœ‰è½»å¾®æ”¹å–„")
            else:
                print(f"   âš ï¸ å±‚æ¬¡åŒ–æŸå¤±éœ€è¦è°ƒä¼˜æƒé‡é…ç½®")
            
            if avg_level_1 > 0.01 and avg_level_4 < 0:
                print(f"   ğŸ¯ æˆåŠŸå®ç°'ç‰ºç‰²ç»†èŠ‚æ¢å–åŸºç¡€å‡†ç¡®æ€§'ç­–ç•¥")
            elif avg_level_1 > 0 and avg_level_4 > 0:
                print(f"   ğŸ† å®ç°åŒèµ¢ï¼šåŸºç¡€å’Œç»†èŠ‚å‡†ç¡®æ€§éƒ½æœ‰æå‡")
            
            # æœ€ä½³ç»„åˆ
            if summary['best_hierarchical_combo']:
                best = summary['best_hierarchical_combo']
                best_model_short = best['model_name'].split('/')[-1]
                print(f"   ğŸ… æœ€ä½³ç»„åˆ: {best_model_short} + {best['data_type']}")
                print(f"      åŠ æƒæ”¹è¿›: {best['weighted_improvement']:+.4f}")

        print(f"\nğŸ“ è¯¦ç»†ç»“æœä¿å­˜åœ¨: {results_dir}")
        print(f"   - enhanced_hierarchical_report.json: å±‚æ¬¡åŒ–åˆ†ææŠ¥å‘Š")
        print(f"   - hierarchical_comparison_results.csv: åŸå§‹æ•°æ®")
def main():
    """ä¸»å‡½æ•° - ä¼˜åŒ–ç‰ˆ"""
    print("ğŸ”¬ å±‚æ¬¡åŒ–æŸå¤±å‡½æ•° + ä¸­æ–‡é¢„å¤„ç†å¯¹æ¯”å®éªŒ (ä¼˜åŒ–ç‰ˆ)")
    print("ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šå¢å¤§batch_size, å‡å°‘epoch, æ•°æ®ç¼“å­˜, æ¿€è¿›æ—©åœ")
    print("=" * 80)
    
    if not HIERARCHICAL_AVAILABLE:
        print("âŒ å±‚æ¬¡åŒ–åŠŸèƒ½ä¸å¯ç”¨")
        return
    
    csv_path = "lunwenimpro/newjob1_sortall.csv"
    
    if not os.path.exists(csv_path):
        print(f"âŒ æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶: {csv_path}")
        return
    
    print("é€‰æ‹©å®éªŒè§„æ¨¡ (ä¼˜åŒ–ç‰ˆ):")
    print("1. å¿«é€Ÿæµ‹è¯• (4Kæ ·æœ¬, 3epoch) - æ¨èç”¨äºè°ƒè¯•")
    print("2. æ ‡å‡†æµ‹è¯• (6Kæ ·æœ¬, 3epoch)")
    print("3. å®Œæ•´æµ‹è¯• (8Kæ ·æœ¬, 3epoch)")
    
    choice = input("è¯·è¾“å…¥é€‰æ‹© (1-3): ")
    
    if choice == "1":
        max_samples = 4000
    elif choice == "2":
        max_samples = 6000
    elif choice == "3":
        max_samples = 8000
    else:
        print("æ— æ•ˆé€‰æ‹©,ä½¿ç”¨å¿«é€Ÿæµ‹è¯•")
        max_samples = 4000
    
    print(f"\nğŸ¯ ä¼˜åŒ–ç‰ˆå®éªŒé…ç½®:")
    print(f"   æ•°æ®æ–‡ä»¶: {csv_path}")
    print(f"   æ ·æœ¬é™åˆ¶: {max_samples}")
    print(f"   æ‰¹æ¬¡å¤§å°: 64 (ä¼˜åŒ–å)")
    print(f"   æœ€å¤§epoch: 3 (ä¼˜åŒ–å)")
    print(f"   æ—©åœè€å¿ƒ: 2 (ä¼˜åŒ–å)")
    print(f"   æµ‹è¯•æ¨¡å‹: ä»…chinese-roberta-wwm-ext (ä¼˜åŒ–å)")
    print(f"   æ•°æ®ç¼“å­˜: å¯ç”¨ (ä¼˜åŒ–å)")
    print(f"   é¢„è®¡å•ä¸ªå®éªŒæ—¶é—´: 300-600ç§’")
    if len(['hfl/chinese-roberta-wwm-ext']) == 1:  # å¦‚æœåªæµ‹è¯•ä¸€ä¸ªæ¨¡å‹
        print(f"   æµ‹è¯•æ¨¡å‹: hfl/chinese-roberta-wwm-ext (ä¼˜åŒ–å)")
    else:  # å¦‚æœæµ‹è¯•å¤šä¸ªæ¨¡å‹
        print(f"   æµ‹è¯•æ¨¡å‹: {len(['bert-base-chinese', 'hfl/chinese-bert-wwm-ext', 'hfl/chinese-roberta-wwm-ext'])} ä¸ªä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹")
    
    print(f"   æ•°æ®ç¼“å­˜: å¯ç”¨ (ä¼˜åŒ–å)")
    print(f"   é¢„è®¡å•ä¸ªå®éªŒæ—¶é—´: 300-600ç§’")
    
    confirm = input(f"\nç¡®è®¤å¼€å§‹ä¼˜åŒ–ç‰ˆå®éªŒ? (y/N): ")
    if confirm.lower() != 'y':
        print("å®éªŒå·²å–æ¶ˆ")
        return
    
    try:
        # åˆ›å»ºä¼˜åŒ–ç‰ˆå®éªŒè¿è¡Œå™¨
        runner = HierarchicalExperimentRunner(csv_path, max_samples)
        
        # è¿è¡Œå¯¹æ¯”å®éªŒ
        results, results_dir = runner.run_hierarchical_comparison()
        
        print(f"\nğŸ‰ ä¼˜åŒ–ç‰ˆå®éªŒå®Œæˆ!")
        print(f"ğŸ“ æŸ¥çœ‹è¯¦ç»†ç»“æœ: {results_dir}")
        
    except Exception as e:
        print(f"âŒ å®éªŒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()