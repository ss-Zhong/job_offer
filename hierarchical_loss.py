#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å±‚æ¬¡åŒ–æŸå¤±å‡½æ•°æ¨¡å—
ä¸ºISCOç¼–ç åˆ†ç±»ä»»åŠ¡è®¾è®¡çš„å¤šçº§åˆ«æƒ©ç½šæŸå¤±å‡½æ•°
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Dict, List, Optional, Tuple


class HierarchicalISCOLoss(nn.Module):
    """
    å±‚æ¬¡åŒ–ISCOæŸå¤±å‡½æ•°
    æ ¹æ®ISCOç¼–ç çš„å±‚æ¬¡ç»“æ„ï¼Œå¯¹ä¸åŒçº§åˆ«çš„åˆ†ç±»é”™è¯¯ç»™äºˆä¸åŒæƒé‡çš„æƒ©ç½š
    """
    
    def __init__(self, 
                 hierarchy: Dict,
                 level_weights: Dict[int, float] = None,
                 base_loss_fn: str = 'cross_entropy',
                 reduction: str = 'mean'):
        """
        Args:
            hierarchy: ISCOå±‚æ¬¡ç»“æ„å­—å…¸
            level_weights: å„çº§åˆ«é”™è¯¯çš„æƒ©ç½šæƒé‡
            base_loss_fn: åŸºç¡€æŸå¤±å‡½æ•°ç±»å‹ ('cross_entropy' or 'focal')
            reduction: æŸå¤±èšåˆæ–¹å¼ ('mean' or 'sum')
        """
        super().__init__()
        
        self.hierarchy = hierarchy
        self.reduction = reduction
        
        # é»˜è®¤æƒé‡ï¼šçº§åˆ«è¶Šé«˜ï¼ˆæ•°å­—è¶Šå°ï¼‰ï¼Œé”™è¯¯æƒ©ç½šè¶Šå¤§
        self.level_weights = level_weights
        
        # æ„å»ºISCOç¼–ç æ˜ å°„
        self._build_isco_mappings()
        
        # é€‰æ‹©åŸºç¡€æŸå¤±å‡½æ•°
        if base_loss_fn == 'cross_entropy':
            self.base_loss = nn.CrossEntropyLoss(reduction='none')
        elif base_loss_fn == 'focal':
            self.base_loss = FocalLoss(reduction='none')
        else:
            raise ValueError(f"Unknown base loss function: {base_loss_fn}")
        
        print(f"âœ… å±‚æ¬¡åŒ–æŸå¤±å‡½æ•°åˆå§‹åŒ–å®Œæˆ")
        print(f"   çº§åˆ«æƒé‡: {self.level_weights}")
        print(f"   åŸºç¡€æŸå¤±: {base_loss_fn}")

    def _build_isco_mappings(self):
        """æ„å»ºISCOç¼–ç æ˜ å°„å…³ç³»"""
        # æå–æ‰€æœ‰4ä½ISCOç¼–ç 
        self.isco_codes = []
        self.code_to_idx = {}
        self.idx_to_code = {}
        
        # åªå¤„ç†4ä½ç¼–ç ï¼ˆæœ€åº•å±‚ï¼‰
        level_4_codes = sorted([
            code for code, info in self.hierarchy.items() 
            if info['level'] == 4
        ])
        
        for idx, code in enumerate(level_4_codes):
            self.isco_codes.append(code)
            self.code_to_idx[code] = idx
            self.idx_to_code[idx] = code
        
        self.num_classes = len(self.isco_codes)
        
        # æ„å»ºå±‚æ¬¡è·ç¦»çŸ©é˜µ
        self._build_hierarchy_distance_matrix()
        
        print(f"   æ„å»ºäº† {self.num_classes} ä¸ªISCO-4çº§ç¼–ç çš„æ˜ å°„")

    def _build_hierarchy_distance_matrix(self):
        """æ„å»ºå±‚æ¬¡è·ç¦»çŸ©é˜µï¼Œç”¨äºè®¡ç®—ä¸åŒç¼–ç ä¹‹é—´çš„å±‚æ¬¡è·ç¦»"""
        n = self.num_classes
        self.hierarchy_distance_matrix = torch.zeros((n, n))
        
        for i in range(n):
            for j in range(n):
                if i == j:
                    continue
                
                code_i = self.idx_to_code[i]
                code_j = self.idx_to_code[j]
                
                # è®¡ç®—ä¸¤ä¸ªç¼–ç çš„å±‚æ¬¡è·ç¦»
                distance = self._calculate_hierarchy_distance(code_i, code_j)
                self.hierarchy_distance_matrix[i, j] = distance

    def _calculate_hierarchy_distance(self, code1: str, code2: str) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªISCOç¼–ç ä¹‹é—´çš„å±‚æ¬¡è·ç¦»
        è¿”å›å€¼åŸºäºæœ€é«˜ä¸åŒçº§åˆ«çš„æƒé‡
        """
        # ä»é«˜åˆ°ä½æ£€æŸ¥æ¯ä¸ªçº§åˆ«
        for level in [1, 2, 3, 4]:
            if code1[:level] != code2[:level]:
                # åœ¨è¿™ä¸ªçº§åˆ«ä¸Šä¸åŒï¼Œè¿”å›å¯¹åº”æƒé‡
                return self.level_weights[level]
        
        # å®Œå…¨ç›¸åŒï¼ˆä¸åº”è¯¥å‘ç”Ÿï¼‰
        return 0.0

    def _get_hierarchy_weights(self, targets: torch.Tensor, predictions: torch.Tensor) -> torch.Tensor:
        """
        æ ¹æ®é¢„æµ‹å’ŒçœŸå®æ ‡ç­¾è®¡ç®—å±‚æ¬¡æƒé‡
        
        Args:
            targets: çœŸå®æ ‡ç­¾ç´¢å¼• [batch_size]
            predictions: é¢„æµ‹çš„ç±»åˆ«ç´¢å¼• [batch_size]
        
        Returns:
            weights: æ¯ä¸ªæ ·æœ¬çš„å±‚æ¬¡æƒé‡ [batch_size]
        """
        batch_size = targets.shape[0]
        weights = torch.ones(batch_size, device=targets.device)
        
        for i in range(batch_size):
            true_idx = targets[i].item()
            pred_idx = predictions[i].item()
            
            if true_idx != pred_idx:
                # è·å–å±‚æ¬¡è·ç¦»ä½œä¸ºæƒé‡
                weights[i] = self.hierarchy_distance_matrix[true_idx, pred_idx].item()
        
        return weights

    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        """
        è®¡ç®—å±‚æ¬¡åŒ–æŸå¤±
        
        Args:
            logits: æ¨¡å‹è¾“å‡ºçš„logits [batch_size, num_classes]
            targets: çœŸå®æ ‡ç­¾ç´¢å¼• [batch_size]
        
        Returns:
            loss: å±‚æ¬¡åŒ–åŠ æƒæŸå¤±
        """
        # è®¡ç®—åŸºç¡€æŸå¤±
        base_loss = self.base_loss(logits, targets)
        
        # è·å–é¢„æµ‹ç±»åˆ«
        predictions = torch.argmax(logits, dim=1)
        
        # è®¡ç®—å±‚æ¬¡æƒé‡
        hierarchy_weights = self._get_hierarchy_weights(targets, predictions)
        
        # åº”ç”¨å±‚æ¬¡æƒé‡
        weighted_loss = base_loss * hierarchy_weights
        
        # èšåˆæŸå¤±
        if self.reduction == 'mean':
            return weighted_loss.mean()
        elif self.reduction == 'sum':
            return weighted_loss.sum()
        else:
            return weighted_loss
    
    def get_detailed_loss_info(self, logits: torch.Tensor, targets: torch.Tensor) -> Dict:
        """è·å–è¯¦ç»†çš„æŸå¤±ä¿¡æ¯ï¼Œç”¨äºåˆ†æå’Œè°ƒè¯•"""
        with torch.no_grad():
            predictions = torch.argmax(logits, dim=1)
            
            # ç»Ÿè®¡å„çº§åˆ«çš„é”™è¯¯
            level_errors = {1: 0, 2: 0, 3: 0, 4: 0}
            correct = 0
            
            for i in range(len(targets)):
                true_idx = targets[i].item()
                pred_idx = predictions[i].item()
                
                if true_idx == pred_idx:
                    correct += 1
                else:
                    true_code = self.idx_to_code[true_idx]
                    pred_code = self.idx_to_code[pred_idx]
                    
                    # æ‰¾å‡ºé”™è¯¯çº§åˆ«
                    for level in [1, 2, 3, 4]:
                        if true_code[:level] != pred_code[:level]:
                            level_errors[level] += 1
                            break
            
            # è®¡ç®—æŸå¤±
            loss = self.forward(logits, targets)
            
            return {
                'total_loss': loss.item(),
                'accuracy': correct / len(targets),
                'level_1_errors': level_errors[1],
                'level_2_errors': level_errors[2],
                'level_3_errors': level_errors[3],
                'level_4_errors': level_errors[4],
                'total_errors': sum(level_errors.values())
            }


class FocalLoss(nn.Module):
    """Focal Loss for addressing class imbalance"""
    
    def __init__(self, alpha: float = 1.0, gamma: float = 2.0, reduction: str = 'mean'):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction

    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        ce_loss = F.cross_entropy(logits, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss
        
        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        else:
            return focal_loss


class HierarchicalMultitaskLoss(nn.Module):
    """
    å¤šä»»åŠ¡å±‚æ¬¡åŒ–æŸå¤±å‡½æ•°
    åŒæ—¶é¢„æµ‹å¤šä¸ªçº§åˆ«çš„ISCOç¼–ç 
    """
    
    def __init__(self,
                 hierarchy: Dict,
                 task_weights: Dict[int, float] = None,
                 level_weights: Dict[int, float] = None):
        """
        Args:
            hierarchy: ISCOå±‚æ¬¡ç»“æ„
            task_weights: å„ä»»åŠ¡ï¼ˆçº§åˆ«ï¼‰çš„æƒé‡ {1: 0.1, 2: 0.2, 3: 0.3, 4: 0.4}
            level_weights: å„çº§åˆ«é”™è¯¯çš„æƒ©ç½šæƒé‡
        """
        super().__init__()
        
        self.hierarchy = hierarchy
        
        # ä»»åŠ¡æƒé‡ï¼ˆè¶Šç²¾ç»†çš„çº§åˆ«æƒé‡è¶Šé«˜ï¼‰
        self.task_weights = task_weights or {
            1: 0.1,  # ä¸€çº§åˆ†ç±»ä»»åŠ¡æƒé‡
            2: 0.2,  # äºŒçº§åˆ†ç±»ä»»åŠ¡æƒé‡
            3: 0.3,  # ä¸‰çº§åˆ†ç±»ä»»åŠ¡æƒé‡
            4: 0.4   # å››çº§åˆ†ç±»ä»»åŠ¡æƒé‡ï¼ˆæœ€é‡è¦ï¼‰
        }
        
        # æ„å»ºå„çº§åˆ«çš„ç±»åˆ«æ˜ å°„
        self._build_level_mappings()
        
        # ä¸ºæ¯ä¸ªçº§åˆ«åˆ›å»ºæŸå¤±å‡½æ•°
        self.level_losses = nn.ModuleDict()
        for level in [1, 2, 3, 4]:
            self.level_losses[str(level)] = nn.CrossEntropyLoss()
        
        # ä¸»è¦çš„å±‚æ¬¡åŒ–æŸå¤±ï¼ˆç”¨äº4çº§åˆ†ç±»ï¼‰
        self.hierarchical_loss = HierarchicalISCOLoss(
            hierarchy=hierarchy,
            level_weights=level_weights
        )

    def _build_level_mappings(self):
        """æ„å»ºå„çº§åˆ«çš„ç¼–ç æ˜ å°„"""
        self.level_mappings = {}
        
        for level in [1, 2, 3, 4]:
            level_codes = sorted(list(set([
                code[:level] for code, info in self.hierarchy.items()
                if info['level'] == 4  # ä»4çº§ç¼–ç æå–
            ])))
            
            self.level_mappings[level] = {
                'codes': level_codes,
                'code_to_idx': {code: idx for idx, code in enumerate(level_codes)},
                'idx_to_code': {idx: code for idx, code in enumerate(level_codes)},
                'num_classes': len(level_codes)
            }

    def forward(self, 
                logits_dict: Dict[int, torch.Tensor], 
                targets: torch.Tensor) -> Tuple[torch.Tensor, Dict]:
        """
        è®¡ç®—å¤šä»»åŠ¡å±‚æ¬¡åŒ–æŸå¤±
        
        Args:
            logits_dict: å„çº§åˆ«çš„é¢„æµ‹logits {1: [B, C1], 2: [B, C2], 3: [B, C3], 4: [B, C4]}
            targets: 4çº§ISCOç¼–ç çš„ç´¢å¼• [batch_size]
        
        Returns:
            total_loss: æ€»æŸå¤±
            loss_dict: å„éƒ¨åˆ†æŸå¤±çš„è¯¦ç»†ä¿¡æ¯
        """
        loss_dict = {}
        total_loss = 0
        
        # è·å–å„çº§åˆ«çš„çœŸå®æ ‡ç­¾
        target_codes = [self.hierarchical_loss.idx_to_code[idx.item()] for idx in targets]
        
        # è®¡ç®—å„çº§åˆ«çš„æŸå¤±
        for level in [1, 2, 3, 4]:
            if level in logits_dict:
                # è·å–è¯¥çº§åˆ«çš„ç›®æ ‡
                level_targets = []
                for code in target_codes:
                    level_code = code[:level]
                    level_idx = self.level_mappings[level]['code_to_idx'][level_code]
                    level_targets.append(level_idx)
                
                level_targets = torch.tensor(level_targets, device=targets.device)
                
                # è®¡ç®—è¯¥çº§åˆ«çš„æŸå¤±
                if level == 4:
                    # ä½¿ç”¨å±‚æ¬¡åŒ–æŸå¤±
                    level_loss = self.hierarchical_loss(logits_dict[level], targets)
                else:
                    # ä½¿ç”¨æ™®é€šäº¤å‰ç†µ
                    level_loss = self.level_losses[str(level)](logits_dict[level], level_targets)
                
                # åº”ç”¨ä»»åŠ¡æƒé‡
                weighted_loss = self.task_weights[level] * level_loss
                
                loss_dict[f'level_{level}_loss'] = level_loss.item()
                total_loss += weighted_loss
        
        loss_dict['total_loss'] = total_loss.item()
        
        return total_loss, loss_dict


# ä½¿ç”¨ç¤ºä¾‹
def create_hierarchical_loss_example():
    """åˆ›å»ºå±‚æ¬¡åŒ–æŸå¤±å‡½æ•°çš„ä½¿ç”¨ç¤ºä¾‹"""
    
    # æ¨¡æ‹Ÿå±‚æ¬¡ç»“æ„
    hierarchy = {
        '1': {'label': '1', 'level': 1, 'parents': []},
        '11': {'label': '11', 'level': 2, 'parents': ['1']},
        '112': {'label': '112', 'level': 3, 'parents': ['1', '11']},
        '1121': {'label': '1121', 'level': 4, 'parents': ['1', '11', '112']},
        '1122': {'label': '1122', 'level': 4, 'parents': ['1', '11', '112']},
        '2': {'label': '2', 'level': 1, 'parents': []},
        '21': {'label': '21', 'level': 2, 'parents': ['2']},
        '212': {'label': '212', 'level': 3, 'parents': ['2', '21']},
        '2121': {'label': '2121', 'level': 4, 'parents': ['2', '21', '212']}
    }
    
    # åˆ›å»ºæŸå¤±å‡½æ•°
    loss_fn = HierarchicalISCOLoss(
        hierarchy=hierarchy,
        level_weights={1: 8.0, 2: 4.0, 3: 2.0, 4: 1.0}
    )
    
    # æ¨¡æ‹Ÿæ•°æ®
    batch_size = 3
    num_classes = 3  # ç®€åŒ–ç¤ºä¾‹
    
    # æ¨¡æ‹Ÿlogits
    logits = torch.randn(batch_size, num_classes)
    
    # æ¨¡æ‹Ÿç›®æ ‡ï¼ˆä½¿ç”¨ç´¢å¼•ï¼‰
    targets = torch.tensor([0, 1, 2])  # å¯¹åº” '1121', '1122', '2121'
    
    # è®¡ç®—æŸå¤±
    loss = loss_fn(logits, targets)
    
    # è·å–è¯¦ç»†ä¿¡æ¯
    info = loss_fn.get_detailed_loss_info(logits, targets)
    
    print(f"æŸå¤±å€¼: {loss.item():.4f}")
    print(f"è¯¦ç»†ä¿¡æ¯: {info}")
    
    return loss_fn


if __name__ == "__main__":
    print("ğŸ¯ å±‚æ¬¡åŒ–æŸå¤±å‡½æ•°æ¨¡å—")
    print("=" * 50)
    
    # åˆ›å»ºç¤ºä¾‹
    loss_fn = create_hierarchical_loss_example()
    
    print("\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
    print("1. HierarchicalISCOLoss: å•ä»»åŠ¡å±‚æ¬¡åŒ–æŸå¤±")
    print("   - æ ¹æ®ISCOç¼–ç å±‚çº§ç»™äºˆä¸åŒæƒ©ç½šæƒé‡")
    print("   - 1çº§é”™è¯¯æƒ©ç½šæœ€é‡ï¼Œ4çº§é”™è¯¯æƒ©ç½šæœ€è½»")
    print("\n2. HierarchicalMultitaskLoss: å¤šä»»åŠ¡å±‚æ¬¡åŒ–æŸå¤±")
    print("   - åŒæ—¶é¢„æµ‹å¤šä¸ªçº§åˆ«çš„ISCOç¼–ç ")
    print("   - ç»“åˆå±‚æ¬¡åŒ–æƒ©ç½šå’Œå¤šä»»åŠ¡å­¦ä¹ ")