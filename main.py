#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œå…¨å–ä»£main.pyçš„ä¸­æ–‡èŒä¸šåˆ†ç±»è®­ç»ƒè„šæœ¬
æ”¯æŒçœŸå®æ•°æ®è®­ç»ƒ + å‘½ä»¤è¡Œæ¥å£
"""

import os
from datetime import datetime
import click
import numpy as np
import torch
import pandas as pd
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

# Windowså¤šè¿›ç¨‹ä¿®å¤
torch.set_float32_matmul_precision('medium')

from job_offers_classifier.datasets import *
from job_offers_classifier.job_offers_classfier import *
from job_offers_classifier.job_offers_utils import *
from job_offers_classifier.load_save import *


@click.command()
# Command
@click.argument("command", type=str)
@click.argument("classifier", type=str)
# General settings
@click.option("-x", "--x_data", type=str, required=True)
@click.option("-y", "--y_data", type=str, required=False, default="")
@click.option("-h", "--hierarchy_data", type=str, required=False, default="")
@click.option("-m", "--model_dir", type=str, required=True, default="model")
# Transformer model settings
@click.option("-t", "--transformer_model", type=str, required=False, default="hfl/chinese-roberta-wwm-ext")
@click.option("-tc", "--transformer_ckpt_path", type=str, required=False, default="")
@click.option("-mm", "--modeling_mode", type=str, required=False, default="bottom-up")
# Training parameters
@click.option("-l", "--learning_rate", type=float, required=False, default=2e-5)
@click.option("-w", "--weight_decay", type=float, required=False, default=0.01)
@click.option("-e", "--max_epochs", type=int, required=False, default=10)
@click.option("-b", "--batch_size", type=int, required=False, default=16)
@click.option("-s", "--max_sequence_length", type=int, required=False, default=256)
# Early stopping
@click.option("--early_stopping", type=bool, required=False, default=True)
@click.option("--early_stopping_delta", type=float, required=False, default=0.001)
@click.option("--early_stopping_patience", type=int, required=False, default=3)
# Hardware
@click.option("-T", "--threads", type=int, required=False, default=0)  # é»˜è®¤0é¿å…å¤šè¿›ç¨‹é—®é¢˜
@click.option("-D", "--devices", type=int, required=False, default=1)
@click.option("-P", "--precision", type=str, required=False, default="16-mixed")  # æ”¹ä¸ºå­—ç¬¦ä¸²æ”¯æŒ16-mixed
@click.option("-A", "--accelerator", type=str, required=False, default="auto")
# Linear model
@click.option("--eps", type=float, required=False, default=0.001)
@click.option("-c", "--cost", type=float, required=False, default=10)
@click.option("-E", "--ensemble", type=int, required=False, default=1)
@click.option("--use_provided_hierarchy", type=int, required=False, default=1)
@click.option("--tfidf_vectorizer_min_df", type=int, required=False, default=2)
# æ–°å¢åŠŸèƒ½é€‰é¡¹
@click.option("--language", type=str, required=False, default="zh", help="Language for text processing")
@click.option("--csv_mode", type=bool, required=False, default=False, help="Use CSV file with auto split")
@click.option("--test_size", type=float, required=False, default=0.2, help="Test set ratio for CSV mode")
@click.option("--val_texts", type=str, required=False, default="", help="Validation texts file")
@click.option("--val_labels", type=str, required=False, default="", help="Validation labels file")
# Prediction
@click.option("-p", "--pred_path", type=str, required=False, default="")
@click.option("-S", "--seed", type=int, required=False, default=1993)
@click.option("-v", "--verbose", type=bool, required=False, default=True)
def main(command: str,
         classifier: str,
         x_data: str,
         y_data: str,
         hierarchy_data: str,
         model_dir: str,

         transformer_model: str,
         transformer_ckpt_path: str,
         modeling_mode: str,

         learning_rate: float,
         weight_decay: float,
         max_epochs: int,
         batch_size: int,
         max_sequence_length: int,

         early_stopping: bool,
         early_stopping_delta: float,
         early_stopping_patience: int,

         threads: int,
         devices: int,
         precision: str,  # æ”¹ä¸ºå­—ç¬¦ä¸²
         accelerator: str,

         eps: float,
         cost: float,
         ensemble: int,
         use_provided_hierarchy: int,
         tfidf_vectorizer_min_df: int,

         language: str,
         csv_mode: bool,
         test_size: float,
         val_texts: str,
         val_labels: str,
         pred_path: str,
         seed: int,
         verbose: bool,
         ):

    # è®¾ç½®çº¿ç¨‹æ•°
    if threads <= 0:
        threads = 0  # ç¦ç”¨å¤šè¿›ç¨‹
    
    # GPUè®¾å¤‡æ£€æµ‹
    if torch.cuda.is_available():
        devices = min(devices, torch.cuda.device_count())
        if accelerator == "auto":
            accelerator = "gpu"
    else:
        if accelerator == "auto":
            accelerator = "cpu"
        devices = 1
        
    print(f"ğŸš€ Starting {command} with {classifier}")
    print(f"â° Time: {datetime.now()}")
    print(f"ğŸŒ Language: {language}")
    print(f"ğŸ¤– Model: {transformer_model}")
    print(f"ğŸ’» Device: {accelerator.upper()}")
    if torch.cuda.is_available():
        print(f"ğŸ® GPU: {torch.cuda.get_device_name(0)}")

    if command == 'fit':
        if csv_mode or x_data.endswith('.csv'):
            # CSVæ¨¡å¼ï¼šè‡ªåŠ¨å¤„ç†CSVæ–‡ä»¶
            print(f"\nğŸ“Š CSVæ¨¡å¼ï¼šå¤„ç† {x_data}")
            X, y, hierarchy, X_val, y_val = process_csv_file(x_data, hierarchy_data, test_size, seed, verbose)
        else:
            # ä¼ ç»Ÿæ¨¡å¼ï¼šåˆ†åˆ«åŠ è½½æ–‡ä»¶
            print(f"\nğŸ“ ä¼ ç»Ÿæ¨¡å¼ï¼šåˆ†åˆ«åŠ è½½æ–‡ä»¶")
            if not hierarchy_data:
                raise ValueError("ä¼ ç»Ÿæ¨¡å¼éœ€è¦æä¾›hierarchy_data")
            
            hierarchy_df = load_to_df(hierarchy_data)
            hierarchy = create_hierarchy(hierarchy_df)
            
            X = load_texts(x_data)
            y = load_texts(y_data)
            
            # åŠ è½½éªŒè¯é›†ï¼ˆå¦‚æœæä¾›ï¼‰
            X_val = None
            y_val = None
            if val_texts and val_labels:
                X_val = load_texts(val_texts)
                y_val = load_texts(val_labels)

        # åˆ›å»ºæ¨¡å‹
        if classifier == "ChineseLinearJobOffersClassifier" or classifier == "LinearJobOffersClassifier":
            model = ChineseLinearJobOffersClassifier(
                model_dir=model_dir,
                hierarchy=hierarchy,
                eps=eps,
                c=cost,
                use_provided_hierarchy=use_provided_hierarchy,
                ensemble=ensemble,
                threads=threads,
                tfidf_vectorizer_min_df=tfidf_vectorizer_min_df,
                verbose=verbose
            )
        elif classifier == "ChineseTransformerJobOffersClassifier" or classifier == "TransformerJobOffersClassifier":
            # éªŒè¯ä¸­æ–‡æ¨¡å‹
            if language == 'zh' and 'chinese' not in transformer_model.lower() and 'hfl' not in transformer_model.lower():
                print(f"âš ï¸  Warning: Using '{transformer_model}' for Chinese text")
                print(f"ğŸ’¡ Consider using 'hfl/chinese-roberta-wwm-ext'")
            
            # å¤„ç†precisionå‚æ•°
            if precision.isdigit():
                precision = int(precision)
            
            model = ChineseTransformerJobOffersClassifier(
                model_dir=model_dir,
                hierarchy=hierarchy,
                transformer_model=transformer_model,
                transformer_ckpt_path=transformer_ckpt_path,
                modeling_mode=modeling_mode,
                learning_rate=learning_rate,
                weight_decay=weight_decay,
                max_epochs=max_epochs,
                batch_size=batch_size,
                max_sequence_length=max_sequence_length,
                early_stopping=early_stopping,
                early_stopping_delta=early_stopping_delta,
                early_stopping_patience=early_stopping_patience,
                devices=devices,
                accelerator=accelerator,
                threads=threads,
                precision=precision,
                verbose=verbose
            )
        else:
            raise ValueError(f'Unknown classifier type: {classifier}')

        # è®­ç»ƒæ¨¡å‹
        print(f"\nğŸ¯ å¼€å§‹è®­ç»ƒ...")
        print(f"   è®­ç»ƒæ ·æœ¬: {len(X):,}")
        if X_val:
            print(f"   éªŒè¯æ ·æœ¬: {len(X_val):,}")
        print(f"   ç±»åˆ«æ•°é‡: {len(set(y))}")
        
        model.fit(y, X, y_val=y_val, X_val=X_val)
        print(f"âœ… è®­ç»ƒå®Œæˆï¼")

    elif command == 'predict':
        # é¢„æµ‹æ¨¡å¼
        X = load_texts(x_data)
        
        if classifier == "ChineseLinearJobOffersClassifier" or classifier == "LinearJobOffersClassifier":
            model = ChineseLinearJobOffersClassifier(threads=threads)
        elif classifier == "ChineseTransformerJobOffersClassifier" or classifier == "TransformerJobOffersClassifier":
            # å¤„ç†precisionå‚æ•°
            if precision.isdigit():
                precision = int(precision)
                
            model = ChineseTransformerJobOffersClassifier(
                batch_size=batch_size,
                devices=devices,
                threads=threads,
                precision=precision,
                accelerator=accelerator,
            )
        else:
            raise ValueError(f'Unknown classifier type: {classifier}')
            
        print(f"\nğŸ”® åŠ è½½æ¨¡å‹å¹¶é¢„æµ‹...")
        model.load(model_dir)
        pred, pred_map = model.predict(X)
        
        # ä¿å­˜é¢„æµ‹ç»“æœ
        np.savetxt(pred_path, pred)
        save_as_text(f"{pred_path}.map", list(pred_map.values()))
        print(f"âœ… é¢„æµ‹å®Œæˆï¼ç»“æœä¿å­˜åˆ°: {pred_path}")
        
    else:
        raise ValueError(f'Unknown command: {command}')

    print(f"\nğŸ‰ All done! Time: {datetime.now()}")


def process_csv_file(csv_path, hierarchy_path, test_size, seed, verbose):
    """å¤„ç†CSVæ–‡ä»¶ï¼Œè‡ªåŠ¨åˆ’åˆ†è®­ç»ƒæµ‹è¯•é›†"""
    print(f"ğŸ“Š å¤„ç†CSVæ–‡ä»¶: {csv_path}")
    
    # åŠ è½½CSV
    try:
        df = pd.read_csv(csv_path, encoding='utf-8')
    except UnicodeDecodeError:
        df = pd.read_csv(csv_path, encoding='gbk')
    
    print(f"   æ€»æ ·æœ¬æ•°: {len(df)}")
    
    # æ£€æŸ¥å¿…éœ€çš„åˆ—
    required_cols = ['å²—ä½', 'å²—ä½æè¿°', 'å²—ä½èŒèƒ½', 'ISCO_4_Digit_Code_Gemini']
    missing_cols = [col for col in required_cols if col not in df.columns]
    if missing_cols:
        print(f"âŒ ç¼ºå°‘å¿…éœ€çš„åˆ—: {missing_cols}")
        print(f"   å½“å‰åˆ—: {list(df.columns)}")
        raise ValueError(f"CSVæ–‡ä»¶ç¼ºå°‘å¿…éœ€çš„åˆ—: {missing_cols}")
    
    # ç»„åˆæ–‡æœ¬ç‰¹å¾
    def combine_features(row):
        parts = []
        for col in ['å²—ä½', 'å²—ä½æè¿°', 'å²—ä½èŒèƒ½']:
            if pd.notna(row[col]):
                parts.append(str(row[col]))
        return ' '.join(parts)
    
    df['combined_text'] = df.apply(combine_features, axis=1)
    
    # å¤„ç†ISCOç¼–ç 
    df['isco_code'] = df['ISCO_4_Digit_Code_Gemini'].astype(str).str.zfill(4)
    
    # ç»Ÿè®¡ä¿¡æ¯
    isco_counts = df['isco_code'].value_counts()
    print(f"   å”¯ä¸€ISCOç¼–ç : {len(isco_counts)}")
    print(f"   æœ€é¢‘ç¹çš„5ä¸ªç¼–ç : {isco_counts.head().to_dict()}")
    
    # æ™ºèƒ½åˆ’åˆ†ï¼šç¡®ä¿è®­ç»ƒé›†åŒ…å«æ‰€æœ‰ç±»åˆ«
    rare_threshold = 2
    rare_classes = isco_counts[isco_counts <= rare_threshold].index.tolist()
    common_classes = isco_counts[isco_counts > rare_threshold].index.tolist()
    
    print(f"   ç¨€æœ‰ç±»åˆ« (â‰¤{rare_threshold}æ ·æœ¬): {len(rare_classes)}")
    print(f"   å¸¸è§ç±»åˆ« (>{rare_threshold}æ ·æœ¬): {len(common_classes)}")
    
    # åˆ†åˆ«å¤„ç†ç¨€æœ‰å’Œå¸¸è§ç±»åˆ«
    train_indices = []
    test_indices = []
    
    # ç¨€æœ‰ç±»åˆ«ï¼šè‡³å°‘1ä¸ªåœ¨è®­ç»ƒé›†
    for rare_class in rare_classes:
        rare_samples = df[df['isco_code'] == rare_class].index.tolist()
        if len(rare_samples) == 1:
            train_indices.extend(rare_samples)
        else:
            train_indices.append(rare_samples[0])
            test_indices.extend(rare_samples[1:])
    
    # å¸¸è§ç±»åˆ«ï¼šæ­£å¸¸åˆ†å±‚æŠ½æ ·
    if common_classes:
        common_df = df[df['isco_code'].isin(common_classes)]
        train_common, test_common = train_test_split(
            common_df, test_size=test_size, random_state=seed,
            stratify=common_df['isco_code']
        )
        train_indices.extend(train_common.index.tolist())
        test_indices.extend(test_common.index.tolist())
    
    # åˆ›å»ºè®­ç»ƒå’Œæµ‹è¯•é›†
    train_df = df.loc[train_indices]
    test_df = df.loc[test_indices]
    
    print(f"âœ… æ•°æ®åˆ’åˆ†å®Œæˆ:")
    print(f"   è®­ç»ƒé›†: {len(train_df)} ({len(train_df)/len(df)*100:.1f}%)")
    print(f"   æµ‹è¯•é›†: {len(test_df)} ({len(test_df)/len(df)*100:.1f}%)")
    
    # éªŒè¯æ‰€æœ‰ç±»åˆ«éƒ½åœ¨è®­ç»ƒé›†ä¸­
    train_classes = set(train_df['isco_code'])
    all_classes = set(df['isco_code'])
    if train_classes == all_classes:
        print(f"âœ… è®­ç»ƒé›†åŒ…å«æ‰€æœ‰ {len(all_classes)} ä¸ªISCOç¼–ç ")
    else:
        missing = all_classes - train_classes
        print(f"âš ï¸  è®­ç»ƒé›†ç¼ºå¤±ç¼–ç : {missing}")
    
    # åˆ›å»ºå±‚æ¬¡ç»“æ„
    hierarchy = create_isco_hierarchy_from_codes(df['isco_code'].unique())
    
    # ä¿å­˜æ•°æ®æ–‡ä»¶
    output_dir = os.path.dirname(csv_path)
    train_texts_path = os.path.join(output_dir, "train_texts.txt")
    train_labels_path = os.path.join(output_dir, "train_labels.txt")
    test_texts_path = os.path.join(output_dir, "test_texts.txt")
    test_labels_path = os.path.join(output_dir, "test_labels.txt")
    
    save_as_text(train_texts_path, train_df['combined_text'].tolist())
    save_as_text(train_labels_path, train_df['isco_code'].tolist())
    save_as_text(test_texts_path, test_df['combined_text'].tolist())
    save_as_text(test_labels_path, test_df['isco_code'].tolist())
    
    if verbose:
        print(f"ğŸ’¾ æ•°æ®æ–‡ä»¶å·²ä¿å­˜:")
        print(f"   {train_texts_path}")
        print(f"   {train_labels_path}")
        print(f"   {test_texts_path}")
        print(f"   {test_labels_path}")
    
    return (train_df['combined_text'].tolist(), 
            train_df['isco_code'].tolist(),
            hierarchy,
            test_df['combined_text'].tolist(),
            test_df['isco_code'].tolist())


def create_isco_hierarchy_from_codes(isco_codes):
    """ä»ISCOç¼–ç åˆ›å»ºå±‚æ¬¡ç»“æ„"""
    hierarchy = {}
    
    for code in isco_codes:
        code_str = str(code).zfill(4)
        
        # åˆ›å»ºå„çº§ç¼–ç 
        for level in [1, 2, 3, 4]:
            level_code = code_str[:level]
            if level_code not in hierarchy:
                hierarchy[level_code] = create_hierarchy_node(
                    level_code, 
                    f"ISCO-{level}ä½-{level_code}"
                )
    
    return hierarchy


if __name__ == "__main__":
    main()