#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
èŒä¸šåˆ†ç±»å·¥å…·å‡½æ•°
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional
from collections import Counter


def create_hierarchy_node(class_str: str, name: str) -> Dict:
    """
    åˆ›å»ºå±‚æ¬¡ç»“æ„èŠ‚ç‚¹
    
    Args:
        class_str: ISCOç¼–ç å­—ç¬¦ä¸²
        name: èŠ‚ç‚¹åç§°
        
    Returns:
        å±‚æ¬¡ç»“æ„èŠ‚ç‚¹å­—å…¸
    """
    parents = get_parents(class_str)
    return {
        "parents": parents,
        "label": class_str,
        "name": name,
        "level": len(class_str)  # æ ¹æ®ç¼–ç é•¿åº¦ç¡®å®šå±‚çº§
    }


def get_parents(class_str: str) -> List[str]:
    """
    è·å–ISCOç¼–ç çš„çˆ¶çº§ç¼–ç 
    
    Args:
        class_str: ISCOç¼–ç å­—ç¬¦ä¸²
        
    Returns:
        çˆ¶çº§ç¼–ç åˆ—è¡¨
    """
    parents = []
    for digit in [1, 2, 3]:  # å¯¹äº4ä½ç¼–ç ï¼Œçˆ¶çº§ä¸º1ã€2ã€3ä½
        if len(class_str) > digit:
            parents.append(class_str[:digit])
    return parents


def create_hierarchy_from_isco_codes(isco_codes: List[str]) -> Dict:
    """
    ä»ISCOç¼–ç åˆ—è¡¨åˆ›å»ºå±‚æ¬¡ç»“æ„
    
    Args:
        isco_codes: ISCOç¼–ç åˆ—è¡¨
        
    Returns:
        å±‚æ¬¡ç»“æ„å­—å…¸
    """
    hierarchy = {}
    
    # ç¡®ä¿æ‰€æœ‰ç¼–ç éƒ½æ˜¯å­—ç¬¦ä¸²æ ¼å¼
    isco_codes = [str(code).zfill(4) for code in isco_codes if pd.notna(code)]
    unique_codes = sorted(set(isco_codes))
    
    # ä¸ºæ¯ä¸ªå”¯ä¸€ç¼–ç åˆ›å»ºå±‚æ¬¡ç»“æ„
    all_codes_to_create = set()
    
    for code in unique_codes:
        # æ·»åŠ å½“å‰ç¼–ç 
        all_codes_to_create.add(code)
        
        # æ·»åŠ æ‰€æœ‰çˆ¶çº§ç¼–ç 
        for level in [1, 2, 3]:
            if len(code) > level:
                parent_code = code[:level]
                all_codes_to_create.add(parent_code)
    
    # åˆ›å»ºå±‚æ¬¡ç»“æ„èŠ‚ç‚¹
    for code in sorted(all_codes_to_create):
        if code not in hierarchy:
            hierarchy[code] = create_hierarchy_node(
                code, 
                f"ISCO-{len(code)}ä½-{code}"
            )
    
    return hierarchy


def analyze_isco_distribution(df: pd.DataFrame, 
                            isco_field: str = 'ISCO_4_Digit_Code_Gemini') -> Dict:
    """
    åˆ†æISCOç¼–ç åˆ†å¸ƒ
    
    Args:
        df: æ•°æ®æ¡†
        isco_field: ISCOç¼–ç å­—æ®µå
        
    Returns:
        åˆ†æç»“æœå­—å…¸
    """
    print(f"ğŸ“Š ISCOç¼–ç åˆ†å¸ƒåˆ†æ:")
    
    # åŸºæœ¬ç»Ÿè®¡
    total_samples = len(df)
    unique_codes = df[isco_field].nunique()
    
    print(f"   æ€»æ ·æœ¬æ•°: {total_samples:,}")
    print(f"   å”¯ä¸€ISCOç¼–ç : {unique_codes}")
    
    # å„çº§åˆ«ç»Ÿè®¡
    df_copy = df.copy()
    df_copy['isco_str'] = df_copy[isco_field].astype(str).str.zfill(4)
    
    level_stats = {}
    for level in [1, 2, 3, 4]:
        level_codes = df_copy['isco_str'].str[:level].nunique()
        level_stats[level] = level_codes
        print(f"   {level}ä½ç¼–ç æ•°é‡: {level_codes}")
    
    # é¢‘ç‡åˆ†å¸ƒ
    code_counts = df[isco_field].value_counts()
    print(f"\nğŸ“ˆ é¢‘ç‡åˆ†å¸ƒ:")
    print(f"   æœ€é¢‘ç¹çš„5ä¸ªç¼–ç :")
    for code, count in code_counts.head().items():
        print(f"     {code}: {count} æ¬¡ ({count/total_samples*100:.2f}%)")
    
    # ç¨€æœ‰ç¼–ç ç»Ÿè®¡
    rare_threshold = 5
    rare_codes = code_counts[code_counts <= rare_threshold]
    print(f"\nâš ï¸  ç¨€æœ‰ç¼–ç  (â‰¤{rare_threshold}ä¸ªæ ·æœ¬):")
    print(f"   æ•°é‡: {len(rare_codes)}")
    print(f"   å æ¯”: {len(rare_codes)/unique_codes*100:.2f}%")
    
    return {
        'total_samples': total_samples,
        'unique_codes': unique_codes,
        'level_stats': level_stats,
        'code_counts': code_counts,
        'rare_codes': rare_codes
    }


def prepare_chinese_job_text(df: pd.DataFrame, 
                            text_columns: List[str] = ['å²—ä½', 'å²—ä½æè¿°', 'å²—ä½èŒèƒ½']) -> pd.DataFrame:
    """
    å‡†å¤‡ä¸­æ–‡èŒä¸šæ–‡æœ¬æ•°æ®
    
    Args:
        df: æ•°æ®æ¡†
        text_columns: è¦ç»„åˆçš„æ–‡æœ¬åˆ—
        
    Returns:
        å¤„ç†åçš„æ•°æ®æ¡†
    """
    print(f"ğŸ“ å‡†å¤‡ä¸­æ–‡èŒä¸šæ–‡æœ¬æ•°æ®...")
    
    def combine_text_features(row):
        parts = []
        for col in text_columns:
            if col in row and pd.notna(row[col]) and str(row[col]).strip():
                parts.append(str(row[col]).strip())
        return ' '.join(parts)
    
    # ç»„åˆæ–‡æœ¬
    df['combined_text'] = df.apply(combine_text_features, axis=1)
    
    # æ–‡æœ¬è´¨é‡æ£€æŸ¥
    text_lengths = df['combined_text'].str.len()
    print(f"   å¹³å‡æ–‡æœ¬é•¿åº¦: {text_lengths.mean():.0f} å­—ç¬¦")
    print(f"   æœ€çŸ­æ–‡æœ¬: {text_lengths.min()} å­—ç¬¦")
    print(f"   æœ€é•¿æ–‡æœ¬: {text_lengths.max()} å­—ç¬¦")
    
    # æ£€æŸ¥ç©ºæ–‡æœ¬
    empty_texts = df['combined_text'].str.strip().eq('').sum()
    if empty_texts > 0:
        print(f"âš ï¸  å‘ç° {empty_texts} ä¸ªç©ºæ–‡æœ¬")
        # ç§»é™¤ç©ºæ–‡æœ¬
        df = df[df['combined_text'].str.strip() != ''].copy()
        print(f"   ç§»é™¤åå‰©ä½™: {len(df)} æ¡è®°å½•")
    
    return df


def validate_data_quality(df: pd.DataFrame, 
                         text_col: str = 'combined_text', 
                         label_col: str = 'ISCO_4_Digit_Code_Gemini') -> List[str]:
    """
    éªŒè¯æ•°æ®è´¨é‡
    
    Args:
        df: æ•°æ®æ¡†
        text_col: æ–‡æœ¬åˆ—å
        label_col: æ ‡ç­¾åˆ—å
        
    Returns:
        é—®é¢˜åˆ—è¡¨
    """
    print(f"ğŸ” æ•°æ®è´¨é‡éªŒè¯...")
    
    issues = []
    
    # æ£€æŸ¥ç¼ºå¤±å€¼
    if df[text_col].isnull().sum() > 0:
        issues.append(f"æ–‡æœ¬åˆ—æœ‰ {df[text_col].isnull().sum()} ä¸ªç¼ºå¤±å€¼")
    
    if df[label_col].isnull().sum() > 0:
        issues.append(f"æ ‡ç­¾åˆ—æœ‰ {df[label_col].isnull().sum()} ä¸ªç¼ºå¤±å€¼")
    
    # æ£€æŸ¥ç©ºæ–‡æœ¬
    empty_texts = df[text_col].str.strip().eq('').sum()
    if empty_texts > 0:
        issues.append(f"æœ‰ {empty_texts} ä¸ªç©ºæ–‡æœ¬")
    
    # æ£€æŸ¥æ–‡æœ¬é•¿åº¦
    very_short = (df[text_col].str.len() < 10).sum()
    if very_short > 0:
        issues.append(f"æœ‰ {very_short} ä¸ªè¿‡çŸ­æ–‡æœ¬ (<10å­—ç¬¦)")
    
    very_long = (df[text_col].str.len() > 1000).sum()
    if very_long > 0:
        issues.append(f"æœ‰ {very_long} ä¸ªè¿‡é•¿æ–‡æœ¬ (>1000å­—ç¬¦)")
    
    # æ£€æŸ¥æ ‡ç­¾æ ¼å¼
    invalid_labels = df[label_col].astype(str).str.len().ne(4).sum()
    if invalid_labels > 0:
        issues.append(f"æœ‰ {invalid_labels} ä¸ªé4ä½ISCOç¼–ç ")
    
    if issues:
        print(f"âš ï¸  å‘ç°æ•°æ®è´¨é‡é—®é¢˜:")
        for issue in issues:
            print(f"     - {issue}")
    else:
        print(f"âœ… æ•°æ®è´¨é‡è‰¯å¥½")
    
    return issues


def split_data_by_hierarchy(df: pd.DataFrame, 
                           label_col: str = 'isco_code',
                           test_size: float = 0.2,
                           random_state: int = 42) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    è€ƒè™‘å±‚æ¬¡ç»“æ„çš„æ•°æ®åˆ’åˆ†
    
    Args:
        df: æ•°æ®æ¡†
        label_col: æ ‡ç­¾åˆ—å
        test_size: æµ‹è¯•é›†æ¯”ä¾‹
        random_state: éšæœºç§å­
        
    Returns:
        è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    """
    from sklearn.model_selection import train_test_split
    
    # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
    label_counts = Counter(df[label_col])
    
    # åˆ†ç¦»å•æ ·æœ¬å’Œå¤šæ ·æœ¬ç±»åˆ«
    single_sample_classes = [label for label, count in label_counts.items() if count == 1]
    multi_sample_classes = [label for label, count in label_counts.items() if count > 1]
    
    print(f"ğŸ“Š æ•°æ®åˆ’åˆ†:")
    print(f"   å•æ ·æœ¬ç±»åˆ«: {len(single_sample_classes)}")
    print(f"   å¤šæ ·æœ¬ç±»åˆ«: {len(multi_sample_classes)}")
    
    # å•æ ·æœ¬ç±»åˆ«å…¨éƒ¨æ”¾å…¥è®­ç»ƒé›†
    train_dfs = []
    test_dfs = []
    
    if single_sample_classes:
        single_df = df[df[label_col].isin(single_sample_classes)]
        train_dfs.append(single_df)
    
    # å¤šæ ·æœ¬ç±»åˆ«è¿›è¡Œåˆ†å±‚åˆ’åˆ†
    if multi_sample_classes:
        multi_df = df[df[label_col].isin(multi_sample_classes)]
        
        try:
            train_multi, test_multi = train_test_split(
                multi_df, 
                test_size=test_size, 
                random_state=random_state,
                stratify=multi_df[label_col]
            )
        except ValueError:
            # åˆ†å±‚å¤±è´¥ï¼Œä½¿ç”¨éšæœºåˆ’åˆ†
            train_multi, test_multi = train_test_split(
                multi_df, 
                test_size=test_size, 
                random_state=random_state
            )
        
        train_dfs.append(train_multi)
        test_dfs.append(test_multi)
    
    # åˆå¹¶ç»“æœ
    train_df = pd.concat(train_dfs, ignore_index=True) if train_dfs else pd.DataFrame()
    test_df = pd.concat(test_dfs, ignore_index=True) if test_dfs else pd.DataFrame()
    
    print(f"   è®­ç»ƒé›†: {len(train_df)} æ ·æœ¬")
    print(f"   æµ‹è¯•é›†: {len(test_df)} æ ·æœ¬")
    
    return train_df, test_df


def calculate_hierarchical_metrics(y_true: List[str], 
                                  y_pred: List[str]) -> Dict:
    """
    è®¡ç®—å±‚æ¬¡åŒ–è¯„ä¼°æŒ‡æ ‡
    
    Args:
        y_true: çœŸå®æ ‡ç­¾
        y_pred: é¢„æµ‹æ ‡ç­¾
        
    Returns:
        å„çº§åˆ«çš„å‡†ç¡®ç‡
    """
    from sklearn.metrics import accuracy_score
    
    metrics = {}
    
    # è®¡ç®—å„çº§åˆ«å‡†ç¡®ç‡
    for level in [1, 2, 3, 4]:
        true_level = [label[:level] for label in y_true]
        pred_level = [label[:level] for label in y_pred]
        
        accuracy = accuracy_score(true_level, pred_level)
        metrics[f'level_{level}_accuracy'] = accuracy
    
    # è®¡ç®—é”™è¯¯åˆ†å¸ƒ
    error_counts = {1: 0, 2: 0, 3: 0, 4: 0}
    for true, pred in zip(y_true, y_pred):
        if true != pred:
            # æ‰¾å‡ºæœ€é«˜ä¸åŒçº§åˆ«
            for level in [1, 2, 3, 4]:
                if true[:level] != pred[:level]:
                    error_counts[level] += 1
                    break
    
    metrics['error_distribution'] = error_counts
    
    return metrics


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("ğŸ”§ èŒä¸šåˆ†ç±»å·¥å…·å‡½æ•°")
    print("=" * 50)
    
    # æµ‹è¯•å±‚æ¬¡ç»“æ„åˆ›å»º
    print("\næµ‹è¯•å±‚æ¬¡ç»“æ„åˆ›å»º:")
    test_codes = ['1121', '1122', '2121', '2122', '3111']
    hierarchy = create_hierarchy_from_isco_codes(test_codes)
    
    print(f"åˆ›å»ºäº† {len(hierarchy)} ä¸ªèŠ‚ç‚¹")
    for code, node in sorted(hierarchy.items())[:5]:
        print(f"  {code}: level={node['level']}, parents={node['parents']}")
    
    # æµ‹è¯•å±‚æ¬¡åŒ–æŒ‡æ ‡è®¡ç®—
    print("\næµ‹è¯•å±‚æ¬¡åŒ–æŒ‡æ ‡è®¡ç®—:")
    y_true = ['1121', '1122', '2121', '2122']
    y_pred = ['1122', '1121', '2121', '1122']  # ç¬¬4ä¸ªæ˜¯1çº§é”™è¯¯
    
    metrics = calculate_hierarchical_metrics(y_true, y_pred)
    print("å„çº§åˆ«å‡†ç¡®ç‡:")
    for level in [1, 2, 3, 4]:
        acc = metrics[f'level_{level}_accuracy']
        print(f"  {level}çº§: {acc:.2%}")
    
    print("\né”™è¯¯åˆ†å¸ƒ:")
    for level, count in metrics['error_distribution'].items():
        print(f"  {level}çº§é”™è¯¯: {count} ä¸ª")