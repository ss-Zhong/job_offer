import pandas as pd
import numpy as np


def concat_to_str(x):
    """è¿æ¥æ–‡æœ¬å­—æ®µ"""
    x = [str(x_i) for x_i in x if x_i == x_i]
    x = [x_i for x_i in x if len(x_i)]
    return ' '.join(x)


def fix_class_str(t):
    """ä¿®å¤ç±»åˆ«å­—ç¬¦ä¸²æ ¼å¼"""
    t = str(t)
    t = t.split('.')[0]
    t = '0' * (6 - len(t)) + t
    return t


def check_code(cl):
    """æ£€æŸ¥ç¼–ç æ˜¯å¦ä¸º6ä½"""
    return len(str(cl)) == 6


def class_to_digit(cl, digit=6):
    """æå–æŒ‡å®šä½æ•°çš„ç±»åˆ«ç¼–ç """
    return str(cl)[:digit]


def get_parents(class_str):
    """è·å–ISCOç¼–ç çš„çˆ¶çº§ç¼–ç """
    parents = []
    for digit in [1, 2, 3]:  # å¯¹äº4ä½ç¼–ç ï¼Œçˆ¶çº§ä¸º1ã€2ã€3ä½
        if len(class_str) > digit:
            parents.append(class_str[:digit])
    return parents


def create_hierarchy_node(class_str, name):
    """åˆ›å»ºå±‚æ¬¡ç»“æ„èŠ‚ç‚¹"""
    parents = get_parents(class_str)
    return {
        "parents": parents, 
        "label": class_str, 
        "name": name, 
        "level": len(class_str)  # æ ¹æ®ç¼–ç é•¿åº¦ç¡®å®šå±‚çº§
    }


def create_hierarchy(df, class_str_field='class', name_field='name'):
    """ä»DataFrameåˆ›å»ºå±‚æ¬¡ç»“æ„"""
    hierarchy = {}
    for i, row in df.iterrows():
        class_code = str(row[class_str_field])
        name = str(row[name_field]) if name_field in row and pd.notna(row[name_field]) else f"ISCO-{class_code}"
        hierarchy[class_code] = create_hierarchy_node(class_code, name)
    return hierarchy


def create_hierarchy_from_isco_codes(isco_codes):
    """ä»ISCOç¼–ç åˆ—è¡¨åˆ›å»ºå±‚æ¬¡ç»“æ„"""
    hierarchy = {}
    
    # ç¡®ä¿æ‰€æœ‰ç¼–ç éƒ½æ˜¯å­—ç¬¦ä¸²æ ¼å¼
    isco_codes = [str(code).zfill(4) for code in isco_codes if pd.notna(code)]
    unique_codes = sorted(set(isco_codes))
    
    # ä¸ºæ¯ä¸ªå”¯ä¸€ç¼–ç åˆ›å»ºå±‚æ¬¡ç»“æ„
    all_codes_to_create = set()
    
    for code in unique_codes:
        # æ·»åŠ å½“å‰ç¼–ç 
        all_codes_to_create.add(code)
        
        # æ·»åŠ æ‰€æœ‰çˆ¶çº§ç¼–ç 
        for level in [1, 2, 3]:
            if len(code) > level:
                parent_code = code[:level]
                all_codes_to_create.add(parent_code)
    
    # åˆ›å»ºå±‚æ¬¡ç»“æ„èŠ‚ç‚¹
    for code in sorted(all_codes_to_create):
        if code not in hierarchy:
            hierarchy[code] = create_hierarchy_node(code, f"ISCO-{len(code)}ä½-{code}")
    
    return hierarchy


def _return_new_dfs(new_dfs):
    """è¿”å›å¤„ç†åçš„DataFrame"""
    if len(new_dfs) == 1:
        new_dfs = new_dfs[0]
    else:
        new_dfs = tuple(new_dfs)
    return new_dfs


def remove_classes(dfs, classes, class_field='class'):
    """ç§»é™¤æŒ‡å®šçš„ç±»åˆ«"""
    if not isinstance(dfs, (list, tuple)):
        dfs = [dfs]

    new_dfs = []
    for df in dfs:
        new_df = df.copy()
        for c in classes:
            index = new_df[class_field].astype(str).str.startswith(c)
            new_df = new_df[~index]
        new_dfs.append(new_df)
    return _return_new_dfs(new_dfs)


def remap_classes(dfs, classes_map, class_field='class'):
    """é‡æ–°æ˜ å°„ç±»åˆ«"""
    if not isinstance(dfs, (list, tuple)):
        dfs = [dfs]

    new_dfs = []
    for df in dfs:
        new_df = df.copy()
        new_df[class_field] = new_df[class_field].apply(lambda x: classes_map.get(x, x))
        new_dfs.append(new_df)
    return _return_new_dfs(new_dfs)


def filter_classes(dfs, classes, class_field='class'):
    """è¿‡æ»¤æŒ‡å®šçš„ç±»åˆ«"""
    if not isinstance(dfs, (list, tuple)):
        dfs = [dfs]

    new_dfs = []
    for df in dfs:
        new_df = df.copy()
        index = new_df[class_field].isin(classes)
        new_df = new_df[index]
        new_dfs.append(new_df)
    return _return_new_dfs(new_dfs)


def top_k_prediction(pred, top_k):
    """è·å–top-ké¢„æµ‹ç»“æœ"""
    top_k_labels = np.flip(np.argsort(pred, axis=1))[:, :top_k]
    top_k_prob = np.take_along_axis(pred, top_k_labels, axis=1)
    return top_k_labels, top_k_prob


def analyze_isco_distribution(df, isco_field='ISCO_4_Digit_Code_Gemini'):
    """åˆ†æISCOç¼–ç åˆ†å¸ƒ"""
    print(f"ğŸ“Š ISCOç¼–ç åˆ†å¸ƒåˆ†æ:")
    
    # åŸºæœ¬ç»Ÿè®¡
    total_samples = len(df)
    unique_codes = df[isco_field].nunique()
    
    print(f"   æ€»æ ·æœ¬æ•°: {total_samples:,}")
    print(f"   å”¯ä¸€ISCOç¼–ç : {unique_codes}")
    
    # å„çº§åˆ«ç»Ÿè®¡
    df_copy = df.copy()
    df_copy['isco_str'] = df_copy[isco_field].astype(str).str.zfill(4)
    
    for level in [1, 2, 3, 4]:
        level_codes = df_copy['isco_str'].str[:level].nunique()
        print(f"   {level}ä½ç¼–ç æ•°é‡: {level_codes}")
    
    # é¢‘ç‡åˆ†å¸ƒ
    code_counts = df[isco_field].value_counts()
    print(f"\nğŸ“ˆ é¢‘ç‡åˆ†å¸ƒ:")
    print(f"   æœ€é¢‘ç¹çš„5ä¸ªç¼–ç :")
    for code, count in code_counts.head().items():
        print(f"     {code}: {count} æ¬¡ ({count/total_samples*100:.2f}%)")
    
    # ç¨€æœ‰ç¼–ç ç»Ÿè®¡
    rare_threshold = 5
    rare_codes = code_counts[code_counts <= rare_threshold]
    print(f"\nâš ï¸  ç¨€æœ‰ç¼–ç  (â‰¤{rare_threshold}ä¸ªæ ·æœ¬):")
    print(f"   æ•°é‡: {len(rare_codes)}")
    print(f"   å æ¯”: {len(rare_codes)/unique_codes*100:.2f}%")
    
    return {
        'total_samples': total_samples,
        'unique_codes': unique_codes,
        'code_counts': code_counts,
        'rare_codes': rare_codes
    }


def prepare_chinese_job_text(df, text_columns=['å²—ä½', 'å²—ä½æè¿°', 'å²—ä½èŒèƒ½']):
    """å‡†å¤‡ä¸­æ–‡èŒä¸šæ–‡æœ¬æ•°æ®"""
    print(f"ğŸ“ å‡†å¤‡ä¸­æ–‡èŒä¸šæ–‡æœ¬æ•°æ®...")
    
    def combine_text_features(row):
        parts = []
        for col in text_columns:
            if col in row and pd.notna(row[col]) and str(row[col]).strip():
                parts.append(str(row[col]).strip())
        return ' '.join(parts)
    
    # ç»„åˆæ–‡æœ¬
    df['combined_text'] = df.apply(combine_text_features, axis=1)
    
    # æ–‡æœ¬è´¨é‡æ£€æŸ¥
    text_lengths = df['combined_text'].str.len()
    print(f"   å¹³å‡æ–‡æœ¬é•¿åº¦: {text_lengths.mean():.0f} å­—ç¬¦")
    print(f"   æœ€çŸ­æ–‡æœ¬: {text_lengths.min()} å­—ç¬¦")
    print(f"   æœ€é•¿æ–‡æœ¬: {text_lengths.max()} å­—ç¬¦")
    
    # æ£€æŸ¥ç©ºæ–‡æœ¬
    empty_texts = df['combined_text'].str.strip().eq('').sum()
    if empty_texts > 0:
        print(f"âš ï¸  å‘ç° {empty_texts} ä¸ªç©ºæ–‡æœ¬")
        # ç§»é™¤ç©ºæ–‡æœ¬
        df = df[df['combined_text'].str.strip() != ''].copy()
        print(f"   ç§»é™¤åå‰©ä½™: {len(df)} æ¡è®°å½•")
    
    return df


def validate_data_quality(df, text_col='combined_text', label_col='ISCO_4_Digit_Code_Gemini'):
    """éªŒè¯æ•°æ®è´¨é‡"""
    print(f"ğŸ” æ•°æ®è´¨é‡éªŒè¯...")
    
    issues = []
    
    # æ£€æŸ¥ç¼ºå¤±å€¼
    if df[text_col].isnull().sum() > 0:
        issues.append(f"æ–‡æœ¬åˆ—æœ‰ {df[text_col].isnull().sum()} ä¸ªç¼ºå¤±å€¼")
    
    if df[label_col].isnull().sum() > 0:
        issues.append(f"æ ‡ç­¾åˆ—æœ‰ {df[label_col].isnull().sum()} ä¸ªç¼ºå¤±å€¼")
    
    # æ£€æŸ¥ç©ºæ–‡æœ¬
    empty_texts = df[text_col].str.strip().eq('').sum()
    if empty_texts > 0:
        issues.append(f"æœ‰ {empty_texts} ä¸ªç©ºæ–‡æœ¬")
    
    # æ£€æŸ¥æ–‡æœ¬é•¿åº¦
    very_short = (df[text_col].str.len() < 10).sum()
    if very_short > 0:
        issues.append(f"æœ‰ {very_short} ä¸ªè¿‡çŸ­æ–‡æœ¬ (<10å­—ç¬¦)")
    
    very_long = (df[text_col].str.len() > 1000).sum()
    if very_long > 0:
        issues.append(f"æœ‰ {very_long} ä¸ªè¿‡é•¿æ–‡æœ¬ (>1000å­—ç¬¦)")
    
    # æ£€æŸ¥æ ‡ç­¾æ ¼å¼
    invalid_labels = df[label_col].astype(str).str.len().ne(4).sum()
    if invalid_labels > 0:
        issues.append(f"æœ‰ {invalid_labels} ä¸ªé4ä½ISCOç¼–ç ")
    
    if issues:
        print(f"âš ï¸  å‘ç°æ•°æ®è´¨é‡é—®é¢˜:")
        for issue in issues:
            print(f"     - {issue}")
    else:
        print(f"âœ… æ•°æ®è´¨é‡è‰¯å¥½")
    
    return issues