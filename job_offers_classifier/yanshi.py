#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸­æ–‡èŒä¸šåˆ†ç±»å®Œæ•´æ¼”ç¤ºæµç¨‹
ä½¿ç”¨å“ˆå·¥å¤§BERTæ¨¡å‹è¿›è¡ŒISCOèŒä¸šç¼–ç åˆ†ç±»
"""

import os
import pandas as pd
import numpy as np
from pathlib import Path

# å¯¼å…¥ä½ çš„åˆ†ç±»å™¨
from job_offers_classifier.job_offers_classfier_old import (
    create_chinese_job_classifier,
    ChineseTransformerJobOffersClassifier,
    get_recommended_chinese_models
)
from job_offers_classifier.job_offers_utils_old import create_hierarchy
from job_offers_classifier.load_save import save_as_text, load_texts

def create_demo_data():
    """åˆ›å»ºæ¼”ç¤ºæ•°æ®"""
    print("ğŸ”„ åˆ›å»ºæ¼”ç¤ºæ•°æ®...")
    
    # 1. åˆ›å»ºISCOå±‚æ¬¡ç»“æ„æ•°æ®
    hierarchy_data = {
        'class': ['1', '11', '111', '1111', '1112', '2', '21', '211', '2111', '2112'],
        'name': [
            'ç»ç†äººå‘˜', 'é¦–å¸­æ‰§è¡Œå®˜å’Œé«˜çº§å®˜å‘˜', 'ç«‹æ³•æœºå…³æˆå‘˜å’Œé«˜çº§å®˜å‘˜', 
            'ç«‹æ³•æœºå…³æˆå‘˜', 'é«˜çº§æ”¿åºœå®˜å‘˜',
            'ä¸“ä¸šæŠ€æœ¯äººå‘˜', 'ç§‘å­¦å’Œå·¥ç¨‹ä¸“ä¸šäººå‘˜', 'ç‰©ç†å’Œåœ°çƒç§‘å­¦ä¸“ä¸šäººå‘˜',
            'ç‰©ç†å­¦å®¶å’Œå¤©æ–‡å­¦å®¶', 'æ°”è±¡å­¦å®¶'
        ]
    }
    hierarchy_df = pd.DataFrame(hierarchy_data)
    
    # 2. åˆ›å»ºä¸­æ–‡èŒä¸šæè¿°è®­ç»ƒæ•°æ®
    job_descriptions = [
        "è´Ÿè´£å…¬å¸æ•´ä½“æˆ˜ç•¥è§„åˆ’ï¼Œåˆ¶å®šå¹´åº¦ç»è¥ç›®æ ‡ï¼Œç®¡ç†é«˜çº§ç®¡ç†å›¢é˜Ÿ",
        "åˆ¶å®šå…¬å¸å‘å±•æˆ˜ç•¥ï¼Œç›‘ç£å„éƒ¨é—¨è¿è¥ï¼Œå‘è‘£äº‹ä¼šæ±‡æŠ¥å·¥ä½œ",
        "å‚ä¸å›½å®¶ç«‹æ³•å·¥ä½œï¼Œå®¡è®®æ³•å¾‹æ³•æ¡ˆï¼Œä»£è¡¨äººæ°‘è¡Œä½¿æƒåŠ›",
        "ç»„ç»‡äººå¤§ä¼šè®®ï¼Œå®¡æŸ¥æ”¿åºœå·¥ä½œæŠ¥å‘Šï¼Œç›‘ç£æ³•å¾‹å®æ–½",
        "åˆ¶å®šæ”¿åºœæ”¿ç­–ï¼Œåè°ƒå„éƒ¨é—¨å·¥ä½œï¼Œå¤„ç†é‡å¤§å…¬å…±äº‹åŠ¡",
        "ä»äº‹ç‰©ç†å­¦ç ”ç©¶ï¼Œè®¾è®¡å®éªŒæ–¹æ¡ˆï¼Œåˆ†æå®éªŒæ•°æ®ï¼Œå‘è¡¨å­¦æœ¯è®ºæ–‡",
        "ç ”ç©¶å¤©ä½“ç‰©ç†ç°è±¡ï¼Œä½¿ç”¨å¤©æ–‡æœ›è¿œé•œè§‚æµ‹ï¼Œåˆ†æå¤©ä½“æ•°æ®",
        "åˆ†ææ°”è±¡æ•°æ®ï¼Œåˆ¶ä½œå¤©æ°”é¢„æŠ¥ï¼Œç ”ç©¶æ°”å€™å˜åŒ–è§„å¾‹",
        "æµ‹é‡å¤§æ°”å‚æ•°ï¼Œå»ºç«‹æ°”è±¡æ¨¡å‹ï¼Œé¢„æµ‹æç«¯å¤©æ°”äº‹ä»¶",
        "ç ”ç©¶é‡å­ç‰©ç†ç†è®ºï¼Œè¿›è¡Œç²’å­ç‰©ç†å®éªŒï¼Œå¼€å‘æ–°çš„ç‰©ç†æ¨¡å‹"
    ]
    
    # å¯¹åº”çš„ISCOç¼–ç 
    job_labels = ['1111', '1111', '1111', '1111', '1112', '2111', '2111', '2112', '2112', '2111']
    
    # 3. åˆ›å»ºæµ‹è¯•æ•°æ®
    test_descriptions = [
        "æ‹…ä»»å…¬å¸CEOï¼Œè´Ÿè´£ä¼ä¸šç®¡ç†å’Œæˆ˜ç•¥å†³ç­–",
        "è¿›è¡Œæ ¸ç‰©ç†ç ”ç©¶ï¼Œæ“ä½œç²’å­åŠ é€Ÿå™¨è®¾å¤‡",
        "åˆ†æå«æ˜Ÿæ°”è±¡å›¾åƒï¼Œé¢„æŠ¥æœªæ¥ä¸‰å¤©å¤©æ°”"
    ]
    test_expected = ['1111', '2111', '2112']  # æœŸæœ›çš„é¢„æµ‹ç»“æœ
    
    return hierarchy_df, job_descriptions, job_labels, test_descriptions, test_expected

def save_demo_files(hierarchy_df, job_descriptions, job_labels, test_descriptions):
    """ä¿å­˜æ¼”ç¤ºæ–‡ä»¶"""
    print("ğŸ’¾ ä¿å­˜æ¼”ç¤ºæ–‡ä»¶...")
    
    # åˆ›å»ºæ¼”ç¤ºç›®å½•
    demo_dir = Path("demo_chinese_job_classification")
    demo_dir.mkdir(exist_ok=True)
    
    # ä¿å­˜å±‚æ¬¡ç»“æ„
    hierarchy_path = demo_dir / "isco_hierarchy.csv"
    hierarchy_df.to_csv(hierarchy_path, index=False, encoding='utf-8')
    
    # ä¿å­˜è®­ç»ƒæ•°æ®
    train_texts_path = demo_dir / "train_texts.txt"
    train_labels_path = demo_dir / "train_labels.txt"
    save_as_text(str(train_texts_path), job_descriptions)
    save_as_text(str(train_labels_path), job_labels)
    
    # ä¿å­˜æµ‹è¯•æ•°æ®
    test_texts_path = demo_dir / "test_texts.txt"
    save_as_text(str(test_texts_path), test_descriptions)
    
    print(f"âœ… æ¼”ç¤ºæ–‡ä»¶å·²ä¿å­˜åˆ°: {demo_dir}")
    return demo_dir, hierarchy_path, train_texts_path, train_labels_path, test_texts_path

def demonstrate_training():
    """æ¼”ç¤ºå®Œæ•´çš„è®­ç»ƒå’Œæµ‹è¯•æµç¨‹"""
    print("ğŸš€ å¼€å§‹ä¸­æ–‡èŒä¸šåˆ†ç±»æ¼”ç¤º")
    print("=" * 60)
    
    # 1. åˆ›å»ºæ¼”ç¤ºæ•°æ®
    hierarchy_df, job_descriptions, job_labels, test_descriptions, test_expected = create_demo_data()
    
    # 2. ä¿å­˜æ¼”ç¤ºæ–‡ä»¶
    demo_dir, hierarchy_path, train_texts_path, train_labels_path, test_texts_path = save_demo_files(
        hierarchy_df, job_descriptions, job_labels, test_descriptions
    )
    
    # 3. æ˜¾ç¤ºæ¨èçš„ä¸­æ–‡æ¨¡å‹
    print("\nğŸ“‹ å¯ç”¨çš„ä¸­æ–‡BERTæ¨¡å‹:")
    models = get_recommended_chinese_models()
    for key, info in models.items():
        status = "â­" if info['recommended'] else "  "
        print(f"  {status} {key}: {info['model_name']}")
        print(f"     {info['description']}")
    
    # 4. åˆ›å»ºå±‚æ¬¡ç»“æ„
    print(f"\nğŸ—ï¸  æ„å»ºISCOå±‚æ¬¡ç»“æ„...")
    hierarchy = create_hierarchy(hierarchy_df)
    print(f"âœ… å±‚æ¬¡ç»“æ„åŒ…å« {len(hierarchy)} ä¸ªèŒä¸šç±»åˆ«")
    
    # 5. åˆ›å»ºåˆ†ç±»å™¨
    print(f"\nğŸ¤– åˆ›å»ºä¸­æ–‡BERTèŒä¸šåˆ†ç±»å™¨...")
    model_dir = demo_dir / "chinese_bert_model"
    
    # ä¸ºäº†æ¼”ç¤ºé€Ÿåº¦ï¼Œä½¿ç”¨è¾ƒå°çš„å‚æ•°
    classifier = create_chinese_job_classifier(
        classifier_type='transformer',
        model_dir=str(model_dir),
        hierarchy=hierarchy,
        transformer_model='hfl/chinese-roberta-wwm-ext',  # å“ˆå·¥å¤§RoBERTa
        max_epochs=2,  # æ¼”ç¤ºç”¨ï¼Œå®é™…åº”è¯¥æ›´å¤š
        batch_size=4,   # æ¼”ç¤ºç”¨å°batch
        learning_rate=2e-5,
        early_stopping=True,
        early_stopping_patience=1,
        verbose=True
    )
    
    print(f"âœ… åˆ†ç±»å™¨é…ç½®å®Œæˆ")
    print(f"   æ¨¡å‹: hfl/chinese-roberta-wwm-ext (å“ˆå·¥å¤§RoBERTa)")
    print(f"   è®­ç»ƒæ ·æœ¬: {len(job_descriptions)} æ¡")
    print(f"   èŒä¸šç±»åˆ«: {len(set(job_labels))} ä¸ª")
    
    # 6. è®­ç»ƒæ¨¡å‹
    print(f"\nğŸ¯ å¼€å§‹è®­ç»ƒ...")
    try:
        classifier.fit(job_labels, job_descriptions)
        print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    except Exception as e:
        print(f"âŒ è®­ç»ƒå‡ºé”™: {e}")
        print("ğŸ’¡ å¦‚æœæ˜¯GPU/CUDAé—®é¢˜ï¼Œå¯ä»¥å°è¯•ä½¿ç”¨CPU:")
        print("   æ·»åŠ å‚æ•°: devices=1, accelerator='cpu'")
        return
    
    # 7. æµ‹è¯•é¢„æµ‹
    print(f"\nğŸ”® æµ‹è¯•é¢„æµ‹...")
    print("æµ‹è¯•æ•°æ®:")
    for i, desc in enumerate(test_descriptions):
        print(f"  {i+1}. {desc[:30]}...")
    
    try:
        # è¿›è¡Œé¢„æµ‹
        predictions_array, pred_mapping = classifier.predict(test_descriptions, format='array', top_k=3)
        predictions_df = classifier.predict(test_descriptions, format='dataframe', top_k=3)
        
        print(f"\nğŸ“Š é¢„æµ‹ç»“æœ:")
        print(predictions_df)
        
        # 8. åˆ†æç»“æœ
        print(f"\nğŸ“ˆ è¯¦ç»†åˆ†æ:")
        for i, (desc, expected) in enumerate(zip(test_descriptions, test_expected)):
            predicted = predictions_df.iloc[i]['class_1']
            confidence = predictions_df.iloc[i]['prob_1']
            
            status = "âœ…" if predicted == expected else "âŒ"
            print(f"{status} æ ·æœ¬ {i+1}:")
            print(f"   æè¿°: {desc[:40]}...")
            print(f"   é¢„æœŸ: {expected}")
            print(f"   é¢„æµ‹: {predicted} (ç½®ä¿¡åº¦: {confidence:.3f})")
            
            # æ˜¾ç¤ºtop-3é¢„æµ‹
            print(f"   Top-3: ", end="")
            for j in range(3):
                cls = predictions_df.iloc[i][f'class_{j+1}']
                prob = predictions_df.iloc[i][f'prob_{j+1}']
                print(f"{cls}({prob:.3f}) ", end="")
            print()
        
        # 9. æ¨¡å‹ä¿¡æ¯
        print(f"\nğŸ”§ æ¨¡å‹ä¿¡æ¯:")
        model_info = classifier.get_model_info()
        for key, value in model_info.items():
            print(f"   {key}: {value}")
            
    except Exception as e:
        print(f"âŒ é¢„æµ‹å‡ºé”™: {e}")
        return
    
    # 10. ä¿å­˜æ¨¡å‹ä½¿ç”¨è¯´æ˜
    print(f"\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
    print(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {model_dir}")
    print(f"åŠ è½½ä½¿ç”¨:")
    print(f"""
    # åŠ è½½å·²è®­ç»ƒçš„æ¨¡å‹
    classifier = ChineseTransformerJobOffersClassifier()
    classifier.load('{model_dir}')
    
    # é¢„æµ‹æ–°æ•°æ®
    new_predictions = classifier.predict(['è½¯ä»¶å·¥ç¨‹å¸ˆå¼€å‘ç§»åŠ¨åº”ç”¨ç¨‹åº'])
    """)
    
    print(f"\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼")

def quick_linear_demo():
    """å¿«é€Ÿçº¿æ€§æ¨¡å‹æ¼”ç¤ºï¼ˆå¦‚æœBERTå¤ªæ…¢ï¼‰"""
    print("âš¡ å¿«é€Ÿçº¿æ€§æ¨¡å‹æ¼”ç¤º")
    print("=" * 40)
    
    # åˆ›å»ºæ•°æ®
    hierarchy_df, job_descriptions, job_labels, test_descriptions, test_expected = create_demo_data()
    hierarchy = create_hierarchy(hierarchy_df)
    
    # åˆ›å»ºçº¿æ€§åˆ†ç±»å™¨ï¼ˆæ›´å¿«ï¼‰
    from job_offers_classifier.job_offers_classfier_old import ChineseLinearJobOffersClassifier
    
    classifier = ChineseLinearJobOffersClassifier(
        model_dir="./demo_linear_model",
        hierarchy=hierarchy,
        verbose=True
    )
    
    print("ğŸ¯ è®­ç»ƒçº¿æ€§æ¨¡å‹...")
    classifier.fit(job_labels, job_descriptions)
    
    print("ğŸ”® é¢„æµ‹ç»“æœ...")
    predictions_df = classifier.predict(test_descriptions, format='dataframe', top_k=3)
    print(predictions_df)
    
    print("âœ… çº¿æ€§æ¨¡å‹æ¼”ç¤ºå®Œæˆï¼")

if __name__ == "__main__":
    print("ä¸­æ–‡èŒä¸šåˆ†ç±»ç³»ç»Ÿæ¼”ç¤º")
    print("ä½¿ç”¨å“ˆå·¥å¤§BERTæ¨¡å‹")
    print("=" * 60)
    
    choice = input("é€‰æ‹©æ¼”ç¤ºæ¨¡å¼:\n1. å®Œæ•´BERTæ¼”ç¤º (éœ€è¦GPUï¼Œè¾ƒæ…¢ä½†æ•ˆæœå¥½)\n2. å¿«é€Ÿçº¿æ€§æ¼”ç¤º (CPUå‹å¥½ï¼Œè¾ƒå¿«)\nè¯·è¾“å…¥ 1 æˆ– 2: ")
    
    if choice == "1":
        demonstrate_training()
    elif choice == "2":
        quick_linear_demo()
    else:
        print("æ— æ•ˆé€‰æ‹©ï¼Œè¿è¡Œå®Œæ•´æ¼”ç¤º...")
        demonstrate_training()