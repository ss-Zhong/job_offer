#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œå…¨ä¿®å¤çš„ä¸­æ–‡èŒä¸šåˆ†ç±»æ¼”ç¤º
æ”¯æŒGPU RTX4080S + Windows
"""

import os
import pandas as pd
import numpy as np
from pathlib import Path

# Windowså¤šè¿›ç¨‹ä¿®å¤
import torch
torch.set_float32_matmul_precision('medium')  # ä¼˜åŒ–Tensor Coreæ€§èƒ½

# ä¿®å¤Windowså¤šè¿›ç¨‹é—®é¢˜
if __name__ == '__main__':
    # å¯¼å…¥ä½ çš„åˆ†ç±»å™¨
    from job_offers_classifier.job_offers_classfier import (
        create_chinese_job_classifier,
        ChineseTransformerJobOffersClassifier,
        ChineseLinearJobOffersClassifier,
        get_recommended_chinese_models
    )
    from job_offers_classifier.job_offers_utils import create_hierarchy
    from job_offers_classifier.load_save import save_as_text, load_texts

    def create_demo_data():
        """åˆ›å»ºæ¼”ç¤ºæ•°æ®"""
        print("ğŸ”„ åˆ›å»ºæ¼”ç¤ºæ•°æ®...")
        
        # 1. åˆ›å»ºISCOå±‚æ¬¡ç»“æ„æ•°æ®
        hierarchy_data = {
            'class': ['1', '11', '111', '1111', '1112', '2', '21', '211', '2111', '2112'],
            'name': [
                'ç»ç†äººå‘˜', 'é¦–å¸­æ‰§è¡Œå®˜å’Œé«˜çº§å®˜å‘˜', 'ç«‹æ³•æœºå…³æˆå‘˜å’Œé«˜çº§å®˜å‘˜', 
                'ç«‹æ³•æœºå…³æˆå‘˜', 'é«˜çº§æ”¿åºœå®˜å‘˜',
                'ä¸“ä¸šæŠ€æœ¯äººå‘˜', 'ç§‘å­¦å’Œå·¥ç¨‹ä¸“ä¸šäººå‘˜', 'ç‰©ç†å’Œåœ°çƒç§‘å­¦ä¸“ä¸šäººå‘˜',
                'ç‰©ç†å­¦å®¶å’Œå¤©æ–‡å­¦å®¶', 'æ°”è±¡å­¦å®¶'
            ]
        }
        hierarchy_df = pd.DataFrame(hierarchy_data)
        
        # 2. åˆ›å»ºä¸­æ–‡èŒä¸šæè¿°è®­ç»ƒæ•°æ®
        job_descriptions = [
            "è´Ÿè´£å…¬å¸æ•´ä½“æˆ˜ç•¥è§„åˆ’ï¼Œåˆ¶å®šå¹´åº¦ç»è¥ç›®æ ‡ï¼Œç®¡ç†é«˜çº§ç®¡ç†å›¢é˜Ÿ",
            "åˆ¶å®šå…¬å¸å‘å±•æˆ˜ç•¥ï¼Œç›‘ç£å„éƒ¨é—¨è¿è¥ï¼Œå‘è‘£äº‹ä¼šæ±‡æŠ¥å·¥ä½œ",
            "å‚ä¸å›½å®¶ç«‹æ³•å·¥ä½œï¼Œå®¡è®®æ³•å¾‹æ³•æ¡ˆï¼Œä»£è¡¨äººæ°‘è¡Œä½¿æƒåŠ›",
            "ç»„ç»‡äººå¤§ä¼šè®®ï¼Œå®¡æŸ¥æ”¿åºœå·¥ä½œæŠ¥å‘Šï¼Œç›‘ç£æ³•å¾‹å®æ–½",
            "åˆ¶å®šæ”¿åºœæ”¿ç­–ï¼Œåè°ƒå„éƒ¨é—¨å·¥ä½œï¼Œå¤„ç†é‡å¤§å…¬å…±äº‹åŠ¡",
            "ä»äº‹ç‰©ç†å­¦ç ”ç©¶ï¼Œè®¾è®¡å®éªŒæ–¹æ¡ˆï¼Œåˆ†æå®éªŒæ•°æ®ï¼Œå‘è¡¨å­¦æœ¯è®ºæ–‡",
            "ç ”ç©¶å¤©ä½“ç‰©ç†ç°è±¡ï¼Œä½¿ç”¨å¤©æ–‡æœ›è¿œé•œè§‚æµ‹ï¼Œåˆ†æå¤©ä½“æ•°æ®",
            "åˆ†ææ°”è±¡æ•°æ®ï¼Œåˆ¶ä½œå¤©æ°”é¢„æŠ¥ï¼Œç ”ç©¶æ°”å€™å˜åŒ–è§„å¾‹",
            "æµ‹é‡å¤§æ°”å‚æ•°ï¼Œå»ºç«‹æ°”è±¡æ¨¡å‹ï¼Œé¢„æµ‹æç«¯å¤©æ°”äº‹ä»¶",
            "ç ”ç©¶é‡å­ç‰©ç†ç†è®ºï¼Œè¿›è¡Œç²’å­ç‰©ç†å®éªŒï¼Œå¼€å‘æ–°çš„ç‰©ç†æ¨¡å‹"
        ]
        
        # å¯¹åº”çš„ISCOç¼–ç 
        job_labels = ['1111', '1111', '1111', '1111', '1112', '2111', '2111', '2112', '2112', '2111']
        
        # 3. åˆ›å»ºæµ‹è¯•æ•°æ®
        test_descriptions = [
            "æ‹…ä»»å…¬å¸CEOï¼Œè´Ÿè´£ä¼ä¸šç®¡ç†å’Œæˆ˜ç•¥å†³ç­–",
            "è¿›è¡Œæ ¸ç‰©ç†ç ”ç©¶ï¼Œæ“ä½œç²’å­åŠ é€Ÿå™¨è®¾å¤‡",
            "åˆ†æå«æ˜Ÿæ°”è±¡å›¾åƒï¼Œé¢„æŠ¥æœªæ¥ä¸‰å¤©å¤©æ°”"
        ]
        test_expected = ['1111', '2111', '2112']
        
        return hierarchy_df, job_descriptions, job_labels, test_descriptions, test_expected

    def save_demo_files(hierarchy_df, job_descriptions, job_labels, test_descriptions):
        """ä¿å­˜æ¼”ç¤ºæ–‡ä»¶"""
        print("ğŸ’¾ ä¿å­˜æ¼”ç¤ºæ–‡ä»¶...")
        
        demo_dir = Path("demo_chinese_job_classification")
        demo_dir.mkdir(exist_ok=True)
        
        hierarchy_path = demo_dir / "isco_hierarchy.csv"
        hierarchy_df.to_csv(hierarchy_path, index=False, encoding='utf-8')
        
        train_texts_path = demo_dir / "train_texts.txt"
        train_labels_path = demo_dir / "train_labels.txt"
        save_as_text(str(train_texts_path), job_descriptions)
        save_as_text(str(train_labels_path), job_labels)
        
        test_texts_path = demo_dir / "test_texts.txt"
        save_as_text(str(test_texts_path), test_descriptions)
        
        print(f"âœ… æ¼”ç¤ºæ–‡ä»¶å·²ä¿å­˜åˆ°: {demo_dir}")
        return demo_dir, hierarchy_path, train_texts_path, train_labels_path, test_texts_path

    def demonstrate_bert_gpu():
        """æ¼”ç¤ºGPU BERTè®­ç»ƒï¼ˆRTX4080Sä¼˜åŒ–ï¼‰"""
        print("ğŸš€ å¼€å§‹ä¸­æ–‡BERTèŒä¸šåˆ†ç±»æ¼”ç¤º (GPUæ¨¡å¼)")
        print("=" * 60)
        
        # 1. åˆ›å»ºæ¼”ç¤ºæ•°æ®
        hierarchy_df, job_descriptions, job_labels, test_descriptions, test_expected = create_demo_data()
        
        # 2. ä¿å­˜æ¼”ç¤ºæ–‡ä»¶
        demo_dir, hierarchy_path, train_texts_path, train_labels_path, test_texts_path = save_demo_files(
            hierarchy_df, job_descriptions, job_labels, test_descriptions
        )
        
        # 3. æ˜¾ç¤ºæ¨èçš„ä¸­æ–‡æ¨¡å‹
        print("\nğŸ“‹ å¯ç”¨çš„ä¸­æ–‡BERTæ¨¡å‹:")
        models = get_recommended_chinese_models()
        for key, info in models.items():
            status = "â­" if info['recommended'] else "  "
            print(f"  {status} {key}: {info['model_name']}")
            print(f"     {info['description']}")
        
        # 4. åˆ›å»ºå±‚æ¬¡ç»“æ„
        print(f"\nğŸ—ï¸  æ„å»ºISCOå±‚æ¬¡ç»“æ„...")
        hierarchy = create_hierarchy(hierarchy_df)
        print(f"âœ… å±‚æ¬¡ç»“æ„åŒ…å« {len(hierarchy)} ä¸ªèŒä¸šç±»åˆ«")
        
        # 5. åˆ›å»ºåˆ†ç±»å™¨ - RTX4080Sä¼˜åŒ–é…ç½®
        print(f"\nğŸ¤– åˆ›å»ºä¸­æ–‡BERTèŒä¸šåˆ†ç±»å™¨...")
        model_dir = demo_dir / "chinese_bert_model"
        
        # RTX4080S + Windowsä¼˜åŒ–é…ç½®
        classifier = create_chinese_job_classifier(
            classifier_type='transformer',
            model_dir=str(model_dir),
            hierarchy=hierarchy,
            transformer_model='hfl/chinese-roberta-wwm-ext',
            max_epochs=3,           # ç¨å¾®å¢åŠ è®­ç»ƒè½®æ•°
            batch_size=8,           # RTX4080Så¯ä»¥å¤„ç†æ›´å¤§batch
            learning_rate=2e-5,
            early_stopping=True,
            early_stopping_patience=2,
            # RTX4080S + Windowsä¼˜åŒ–é…ç½®
            devices=1,
            accelerator="gpu",      # ä½¿ç”¨GPU
            precision="16-mixed",   # æ··åˆç²¾åº¦ï¼Œå……åˆ†åˆ©ç”¨RTX4080S
            threads=0,              # å…³é”®ï¼šç¦ç”¨å¤šè¿›ç¨‹é¿å…Windowsé—®é¢˜
            verbose=True
        )
        
        print(f"âœ… åˆ†ç±»å™¨é…ç½®å®Œæˆ")
        print(f"   æ¨¡å‹: hfl/chinese-roberta-wwm-ext (å“ˆå·¥å¤§RoBERTa)")
        print(f"   è¿è¡Œæ¨¡å¼: GPU (RTX4080S)")
        print(f"   ç²¾åº¦: 16-mixed (Tensor Coreä¼˜åŒ–)")
        print(f"   è®­ç»ƒæ ·æœ¬: {len(job_descriptions)} æ¡")
        print(f"   èŒä¸šç±»åˆ«: {len(set(job_labels))} ä¸ª")
        
        # 6. è®­ç»ƒæ¨¡å‹
        print(f"\nğŸ¯ å¼€å§‹è®­ç»ƒ...")
        try:
            classifier.fit(job_labels, job_descriptions)
            print("âœ… GPUæ¨¡å‹è®­ç»ƒå®Œæˆï¼")
        except Exception as e:
            print(f"âŒ GPUè®­ç»ƒå‡ºé”™: {e}")
            print("ğŸ’¡ å°è¯•CPUæ¨¡å¼...")
            demonstrate_bert_cpu()
            return
        
        # 7. æµ‹è¯•é¢„æµ‹
        print(f"\nğŸ”® æµ‹è¯•é¢„æµ‹...")
        print("æµ‹è¯•æ•°æ®:")
        for i, desc in enumerate(test_descriptions):
            print(f"  {i+1}. {desc[:30]}...")
        
        try:
            # è¿›è¡Œé¢„æµ‹
            predictions_df = classifier.predict(test_descriptions, format='dataframe', top_k=3)
            
            print(f"\nğŸ“Š é¢„æµ‹ç»“æœ:")
            print(predictions_df)
            
            # 8. åˆ†æç»“æœ
            print(f"\nğŸ“ˆ è¯¦ç»†åˆ†æ:")
            for i, (desc, expected) in enumerate(zip(test_descriptions, test_expected)):
                predicted = predictions_df.iloc[i]['class_1']
                confidence = predictions_df.iloc[i]['prob_1']
                
                status = "âœ…" if predicted == expected else "âŒ"
                print(f"{status} æ ·æœ¬ {i+1}:")
                print(f"   æè¿°: {desc[:40]}...")
                print(f"   é¢„æœŸ: {expected}")
                print(f"   é¢„æµ‹: {predicted} (ç½®ä¿¡åº¦: {confidence:.3f})")
                
                # æ˜¾ç¤ºtop-3é¢„æµ‹
                print(f"   Top-3: ", end="")
                for j in range(3):
                    cls = predictions_df.iloc[i][f'class_{j+1}']
                    prob = predictions_df.iloc[i][f'prob_{j+1}']
                    print(f"{cls}({prob:.3f}) ", end="")
                print()
            
            # 9. æ¨¡å‹ä¿¡æ¯
            print(f"\nğŸ”§ æ¨¡å‹ä¿¡æ¯:")
            model_info = classifier.get_model_info()
            for key, value in model_info.items():
                print(f"   {key}: {value}")
                
        except Exception as e:
            print(f"âŒ é¢„æµ‹å‡ºé”™: {e}")
            return
        
        print(f"\nğŸ‰ GPU BERTæ¼”ç¤ºå®Œæˆï¼")

    def demonstrate_bert_cpu():
        """æ¼”ç¤ºCPU BERTè®­ç»ƒï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        print("ğŸš€ å¼€å§‹ä¸­æ–‡BERTèŒä¸šåˆ†ç±»æ¼”ç¤º (CPUæ¨¡å¼)")
        print("=" * 60)
        
        # 1. åˆ›å»ºæ¼”ç¤ºæ•°æ®
        hierarchy_df, job_descriptions, job_labels, test_descriptions, test_expected = create_demo_data()
        
        # 2. ä¿å­˜æ¼”ç¤ºæ–‡ä»¶
        demo_dir, hierarchy_path, train_texts_path, train_labels_path, test_texts_path = save_demo_files(
            hierarchy_df, job_descriptions, job_labels, test_descriptions
        )
        
        # 3. åˆ›å»ºå±‚æ¬¡ç»“æ„
        print(f"\nğŸ—ï¸  æ„å»ºISCOå±‚æ¬¡ç»“æ„...")
        hierarchy = create_hierarchy(hierarchy_df)
        print(f"âœ… å±‚æ¬¡ç»“æ„åŒ…å« {len(hierarchy)} ä¸ªèŒä¸šç±»åˆ«")
        
        # 4. åˆ›å»ºåˆ†ç±»å™¨ - CPUæ¨¡å¼
        print(f"\nğŸ¤– åˆ›å»ºä¸­æ–‡BERTèŒä¸šåˆ†ç±»å™¨...")
        model_dir = demo_dir / "chinese_bert_model_cpu"
        
        # CPUå…¼å®¹æ€§é…ç½®
        classifier = create_chinese_job_classifier(
            classifier_type='transformer',
            model_dir=str(model_dir),
            hierarchy=hierarchy,
            transformer_model='hfl/chinese-roberta-wwm-ext',
            max_epochs=2,
            batch_size=4,           # CPUæ¨¡å¼ç”¨å°batch
            learning_rate=2e-5,
            early_stopping=True,
            early_stopping_patience=1,
            # CPUæ¨¡å¼é…ç½®
            devices=1,
            accelerator='cpu',      # ä½¿ç”¨CPU
            precision=32,           # 32ä½ç²¾åº¦
            threads=0,              # ç¦ç”¨å¤šè¿›ç¨‹
            verbose=True
        )
        
        print(f"âœ… åˆ†ç±»å™¨é…ç½®å®Œæˆ")
        print(f"   æ¨¡å‹: hfl/chinese-roberta-wwm-ext (å“ˆå·¥å¤§RoBERTa)")
        print(f"   è¿è¡Œæ¨¡å¼: CPU (å…¼å®¹æ¨¡å¼)")
        print(f"   è®­ç»ƒæ ·æœ¬: {len(job_descriptions)} æ¡")
        print(f"   èŒä¸šç±»åˆ«: {len(set(job_labels))} ä¸ª")
        
        # 5. è®­ç»ƒæ¨¡å‹
        print(f"\nğŸ¯ å¼€å§‹è®­ç»ƒ...")
        try:
            classifier.fit(job_labels, job_descriptions)
            print("âœ… CPUæ¨¡å‹è®­ç»ƒå®Œæˆï¼")
        except Exception as e:
            print(f"âŒ CPUè®­ç»ƒä¹Ÿå‡ºé”™: {e}")
            print("ğŸ’¡ å°è¯•çº¿æ€§æ¨¡å‹æ¼”ç¤º...")
            quick_linear_demo()
            return
        
        # 6. æµ‹è¯•é¢„æµ‹
        print(f"\nğŸ”® æµ‹è¯•é¢„æµ‹...")
        try:
            predictions_df = classifier.predict(test_descriptions, format='dataframe', top_k=3)
            print(f"\nğŸ“Š é¢„æµ‹ç»“æœ:")
            print(predictions_df)
            print("âœ… CPU BERTæ¼”ç¤ºå®Œæˆï¼")
        except Exception as e:
            print(f"âŒ é¢„æµ‹å‡ºé”™: {e}")

    def quick_linear_demo():
        """å¿«é€Ÿçº¿æ€§æ¨¡å‹æ¼”ç¤º"""
        print("âš¡ å¿«é€Ÿçº¿æ€§æ¨¡å‹æ¼”ç¤º")
        print("=" * 40)
        
        # åˆ›å»ºæ•°æ®
        hierarchy_df, job_descriptions, job_labels, test_descriptions, test_expected = create_demo_data()
        hierarchy = create_hierarchy(hierarchy_df)
        
        # åˆ›å»ºçº¿æ€§åˆ†ç±»å™¨
        classifier = ChineseLinearJobOffersClassifier(
            model_dir="./demo_linear_model",
            hierarchy=hierarchy,
            threads=1,              # å•çº¿ç¨‹é¿å…é—®é¢˜
            verbose=True
        )
        
        print("ğŸ¯ è®­ç»ƒçº¿æ€§æ¨¡å‹...")
        try:
            classifier.fit(job_labels, job_descriptions)
            
            print("ğŸ”® é¢„æµ‹ç»“æœ...")
            predictions_df = classifier.predict(test_descriptions, format='dataframe', top_k=3)
            print(predictions_df)
            
            # è¯¦ç»†åˆ†æ
            print(f"\nğŸ“ˆ è¯¦ç»†åˆ†æ:")
            for i, (desc, expected) in enumerate(zip(test_descriptions, test_expected)):
                predicted = predictions_df.iloc[i]['class_1']
                confidence = predictions_df.iloc[i]['prob_1']
                
                status = "âœ…" if predicted == expected else "âŒ"
                print(f"{status} æ ·æœ¬ {i+1}:")
                print(f"   æè¿°: {desc[:40]}...")
                print(f"   é¢„æœŸ: {expected}")
                print(f"   é¢„æµ‹: {predicted} (ç½®ä¿¡åº¦: {confidence:.3f})")
            
            print("âœ… çº¿æ€§æ¨¡å‹æ¼”ç¤ºå®Œæˆï¼")
            
        except Exception as e:
            print(f"âŒ çº¿æ€§æ¨¡å‹ä¹Ÿå‡ºé”™: {e}")
            print("è¯·æ£€æŸ¥ç¯å¢ƒé…ç½®")

    # ä¸»å‡½æ•°
    print("ä¸­æ–‡èŒä¸šåˆ†ç±»ç³»ç»Ÿæ¼”ç¤º")
    print("ä½¿ç”¨å“ˆå·¥å¤§BERTæ¨¡å‹")
    print("æ”¯æŒRTX4080S GPUåŠ é€Ÿ")
    print("=" * 60)
    
    print("GPUæ£€æµ‹:")
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        print(f"âœ… æ£€æµ‹åˆ°GPU: {gpu_name}")
        print(f"   CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"   PyTorchç‰ˆæœ¬: {torch.__version__}")
    else:
        print("âŒ æœªæ£€æµ‹åˆ°å¯ç”¨çš„GPU")
    
    choice = input("\né€‰æ‹©æ¼”ç¤ºæ¨¡å¼:\n1. BERTæ¼”ç¤º (GPUæ¨¡å¼ï¼ŒRTX4080Sä¼˜åŒ–)\n2. BERTæ¼”ç¤º (CPUæ¨¡å¼ï¼Œå…¼å®¹æ¨¡å¼)\n3. å¿«é€Ÿçº¿æ€§æ¼”ç¤º (æœ€ç¨³å®š)\nè¯·è¾“å…¥ 1ã€2 æˆ– 3: ")
    
    if choice == "1":
        if torch.cuda.is_available():
            demonstrate_bert_gpu()
        else:
            print("âŒ GPUä¸å¯ç”¨ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°CPUæ¨¡å¼")
            demonstrate_bert_cpu()
    elif choice == "2":
        demonstrate_bert_cpu()
    elif choice == "3":
        quick_linear_demo()
    else:
        print("æ— æ•ˆé€‰æ‹©ï¼Œè¿è¡Œæœ€ç¨³å®šçš„çº¿æ€§æ¼”ç¤º...")
        quick_linear_demo()