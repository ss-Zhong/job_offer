#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆä¸­æ–‡BERTè®­ç»ƒæµç¨‹ - é›†æˆæ•°æ®å¢å¼ºä¸é¢„å¤„ç†
åŸºäºåŸæœ‰ä»£ç ï¼Œé›†æˆæ–°çš„æ•°æ®å¢å¼ºåŠŸèƒ½
"""

import os
import time
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import json
import warnings
warnings.filterwarnings('ignore')

import torch
torch.set_float32_matmul_precision('medium')

# å¯¼å…¥åŸæœ‰æ¨¡å—
if __name__ == '__main__':
    from job_offers_classifier.job_offers_classfier_old import (
        ChineseTransformerJobOffersClassifier,
        get_recommended_chinese_models
    )
    from job_offers_classifier.job_offers_utils_old import create_hierarchy_node
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import classification_report, accuracy_score
    
    # å¯¼å…¥æ–°çš„æ•°æ®å¢å¼ºæ¨¡å—
    from chinese_job_data_augmentation import EnhancedJobDataProcessor


class EnhancedModelTrainer:
    """å¢å¼ºç‰ˆæ¨¡å‹è®­ç»ƒå™¨"""
    
    def __init__(self, 
                 data_processor: EnhancedJobDataProcessor,
                 enable_augmentation: bool = True,
                 balance_data: bool = True,
                 target_samples_per_class: int = 8):
        
        self.data_processor = data_processor
        self.enable_augmentation = enable_augmentation
        self.balance_data = balance_data
        self.target_samples_per_class = target_samples_per_class
        
        # æ›´æ–°çš„æ¨¡å‹é…ç½®
        self.ENHANCED_MODELS = {
            'hfl_roberta_enhanced': {
                'name': 'hfl/chinese-roberta-wwm-ext',
                'description': 'HFL Chinese RoBERTa-wwm-ext (æ•°æ®å¢å¼ºç‰ˆ)',
                'learning_rate': 2e-5,
                'batch_size': 16,
                'notes': 'å“ˆå·¥å¤§RoBERTa + æ•°æ®å¢å¼ºï¼Œæ€§èƒ½æœ€ä½³'
            },
            'hfl_bert_enhanced': {
                'name': 'hfl/chinese-bert-wwm-ext',
                'description': 'HFL Chinese BERT-wwm-ext (æ•°æ®å¢å¼ºç‰ˆ)',
                'learning_rate': 2e-5,
                'batch_size': 16,
                'notes': 'å“ˆå·¥å¤§BERT + æ•°æ®å¢å¼ºï¼Œç¨³å®šå¯é '
            },
            'google_bert_enhanced': {
                'name': 'bert-base-chinese',
                'description': 'Google Chinese BERT (æ•°æ®å¢å¼ºç‰ˆ)',
                'learning_rate': 2e-5,
                'batch_size': 16,
                'notes': 'Googleä¸­æ–‡BERT + æ•°æ®å¢å¼º'
            }
        }
    
    def load_and_prepare_enhanced_data(self, csv_path, test_size=0.2, max_samples=None):
        """åŠ è½½å’Œå‡†å¤‡å¢å¼ºæ•°æ®"""
        print(f"ğŸ“Š åŠ è½½å’Œå‡†å¤‡å¢å¼ºæ•°æ®: {csv_path}")
        
        # ä½¿ç”¨å¢å¼ºå¤„ç†å™¨å¤„ç†æ•°æ®
        all_texts, all_labels, processing_stats = self.data_processor.process_csv_data(
            csv_path=csv_path,
            enable_augmentation=self.enable_augmentation,
            balance_data=self.balance_data,
            target_samples_per_class=self.target_samples_per_class
        )
        
        # å¦‚æœè®¾ç½®äº†æœ€å¤§æ ·æœ¬æ•°é™åˆ¶
        if max_samples and len(all_texts) > max_samples:
            # åˆ†å±‚é‡‡æ ·ä¿æŒç±»åˆ«å¹³è¡¡
            from sklearn.model_selection import train_test_split
            all_texts, _, all_labels, _ = train_test_split(
                all_texts, all_labels, 
                train_size=max_samples,
                stratify=all_labels,
                random_state=42
            )
            print(f"   é™åˆ¶æ ·æœ¬æ•°: {len(all_texts)}")
        
        # åˆ’åˆ†è®­ç»ƒæµ‹è¯•é›†
        train_texts, test_texts, train_labels, test_labels = train_test_split(
            all_texts, all_labels,
            test_size=test_size,
            random_state=42,
            stratify=all_labels
        )
        
        # åˆ›å»ºå±‚æ¬¡ç»“æ„
        hierarchy = self.create_isco_hierarchy_from_codes(set(all_labels))
        
        # æ•°æ®ç»Ÿè®¡
        data_info = {
            'total_samples': len(all_texts),
            'train_samples': len(train_texts),
            'test_samples': len(test_texts),
            'num_classes': len(set(all_labels)),
            'augmentation_enabled': self.enable_augmentation,
            'balance_enabled': self.balance_data,
            'original_stats': processing_stats['original_stats'],
            'final_stats': processing_stats['final_stats']
        }
        
        print(f"âœ… å¢å¼ºæ•°æ®å‡†å¤‡å®Œæˆ:")
        print(f"   åŸå§‹æ ·æœ¬: {processing_stats['original_stats']['total_samples']}")
        print(f"   å¢å¼ºåæ ·æœ¬: {processing_stats['final_stats']['total_samples']}")
        print(f"   è®­ç»ƒé›†: {len(train_texts)}")
        print(f"   æµ‹è¯•é›†: {len(test_texts)}")
        print(f"   ç±»åˆ«æ•°: {len(set(all_labels))}")
        
        return (train_texts, train_labels, test_texts, test_labels, hierarchy, data_info)
    
    def create_isco_hierarchy_from_codes(self, isco_codes):
        """ä»ISCOç¼–ç åˆ›å»ºå±‚æ¬¡ç»“æ„"""
        hierarchy = {}
        
        for code in isco_codes:
            code_str = str(code).zfill(4)
            
            for level in [1, 2, 3, 4]:
                level_code = code_str[:level]
                if level_code not in hierarchy:
                    hierarchy[level_code] = create_hierarchy_node(
                        level_code, 
                        f"ISCO-{level}ä½-{level_code}"
                    )
        
        return hierarchy
    
    def train_enhanced_model(self, model_key, model_config, train_texts, train_labels, 
                           test_texts, test_labels, hierarchy, results_dir, 
                           training_config):
        """è®­ç»ƒå¢å¼ºæ¨¡å‹"""
        print(f"\nğŸ¤– å¼€å§‹è®­ç»ƒå¢å¼ºæ¨¡å‹: {model_config['description']}")
        print(f"   æ¨¡å‹: {model_config['name']}")
        print(f"   æ•°æ®å¢å¼º: {'âœ“' if self.enable_augmentation else 'âœ—'}")
        print(f"   æ•°æ®å¹³è¡¡: {'âœ“' if self.balance_data else 'âœ—'}")
        
        start_time = time.time()
        model_dir = results_dir / f"enhanced_model_{model_key}"
        
        try:
            # åˆ›å»ºåˆ†ç±»å™¨ï¼ˆä½¿ç”¨å¢å¼ºé…ç½®ï¼‰
            classifier = ChineseTransformerJobOffersClassifier(
                model_dir=str(model_dir),
                hierarchy=hierarchy,
                transformer_model=model_config['name'],
                learning_rate=model_config['learning_rate'],
                batch_size=model_config['batch_size'],
                max_epochs=training_config['max_epochs'],
                early_stopping=True,
                early_stopping_patience=training_config['patience'],
                max_sequence_length=training_config['max_seq_length'],
                devices=1,
                accelerator="gpu" if torch.cuda.is_available() else "cpu",
                precision="16-mixed" if torch.cuda.is_available() else 32,
                threads=0,
                verbose=True
            )
            
            # å‡†å¤‡éªŒè¯é›†
            val_size = min(500, len(test_texts) // 3)
            val_texts = test_texts[:val_size]
            val_labels = test_labels[:val_size]
            final_test_texts = test_texts[val_size:]
            final_test_labels = test_labels[val_size:]
            
            print(f"   è®­ç»ƒæ ·æœ¬: {len(train_texts):,}")
            print(f"   éªŒè¯æ ·æœ¬: {val_size:,}")
            print(f"   æµ‹è¯•æ ·æœ¬: {len(final_test_texts):,}")
            
            # è®­ç»ƒæ¨¡å‹
            print(f"   ğŸ¯ å¼€å§‹è®­ç»ƒ...")
            classifier.fit(train_labels, train_texts, y_val=val_labels, X_val=val_texts)
            
            # é¢„æµ‹
            print(f"   ğŸ”® é¢„æµ‹ä¸­...")
            predictions_df = classifier.predict(final_test_texts, format='dataframe', top_k=5)
            
            # è®¡ç®—æŒ‡æ ‡
            y_true = final_test_labels
            y_pred = predictions_df['class_1'].tolist()
            
            accuracy = accuracy_score(y_true, y_pred)
            top_3_acc = sum(
                true_label in [predictions_df.iloc[i][f'class_{j}'] for j in range(1, 4)]
                for i, true_label in enumerate(y_true)
            ) / len(y_true)
            top_5_acc = sum(
                true_label in [predictions_df.iloc[i][f'class_{j}'] for j in range(1, 6)]
                for i, true_label in enumerate(y_true)
            ) / len(y_true)
            
            training_time = time.time() - start_time
            
            # ä¿å­˜è¯¦ç»†ç»“æœ
            detailed_results = pd.DataFrame({
                'true_label': y_true,
                'predicted_label': y_pred,
                'confidence': predictions_df['prob_1'].tolist(),
                'correct': [t == p for t, p in zip(y_true, y_pred)]
            })
            detailed_results.to_csv(results_dir / f"enhanced_{model_key}_detailed_results.csv", 
                                  index=False, encoding='utf-8')
            
            result = {
                'model_key': model_key,
                'model_name': model_config['name'],
                'description': model_config['description'],
                'notes': model_config['notes'],
                'accuracy': accuracy,
                'top_3_accuracy': top_3_acc,
                'top_5_accuracy': top_5_acc,
                'training_time_minutes': training_time / 60,
                'test_samples': len(final_test_labels),
                'status': 'success',
                'enhancement_info': {
                    'augmentation_enabled': self.enable_augmentation,
                    'balance_enabled': self.balance_data,
                    'target_samples_per_class': self.target_samples_per_class
                }
            }
            
            print(f"âœ… å¢å¼ºæ¨¡å‹è®­ç»ƒå®Œæˆ!")
            print(f"   å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
            print(f"   Top-3å‡†ç¡®ç‡: {top_3_acc:.4f} ({top_3_acc*100:.2f}%)")
            print(f"   Top-5å‡†ç¡®ç‡: {top_5_acc:.4f} ({top_5_acc*100:.2f}%)")
            print(f"   è®­ç»ƒæ—¶é—´: {training_time/60:.1f} åˆ†é’Ÿ")
            
            return result
            
        except Exception as e:
            print(f"âŒ å¢å¼ºæ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return {
                'model_key': model_key,
                'model_name': model_config['name'],
                'description': model_config['description'],
                'accuracy': 0.0,
                'top_3_accuracy': 0.0,
                'top_5_accuracy': 0.0,
                'training_time_minutes': 0.0,
                'test_samples': 0,
                'status': 'failed',
                'error': str(e)
            }
    
    def run_enhanced_comparison(self, csv_path, models_to_test=None, max_samples=None):
        """è¿è¡Œå¢å¼ºç‰ˆæ¨¡å‹å¯¹æ¯”"""
        print("ğŸš€ å¼€å§‹å¢å¼ºç‰ˆä¸­æ–‡BERTæ¨¡å‹å¯¹æ¯”è¯„ä¼°")
        print("ğŸ¯ é›†æˆæ•°æ®å¢å¼ºä¸é¢„å¤„ç†åŠŸèƒ½")
        print("=" * 60)
        
        # åˆ›å»ºç»“æœç›®å½•
        results_dir = Path("enhanced_chinese_bert_comparison")
        results_dir.mkdir(exist_ok=True)
        
        # å‡†å¤‡å¢å¼ºæ•°æ®
        train_texts, train_labels, test_texts, test_labels, hierarchy, data_info = \
            self.load_and_prepare_enhanced_data(csv_path, max_samples=max_samples)
        
        # è®­ç»ƒé…ç½®
        training_config = {
            'max_epochs': 5,  # å¢åŠ epochæ•°ä»¥é€‚åº”å¢å¼ºæ•°æ®
            'patience': 3,
            'max_seq_length': 256
        }
        
        if models_to_test is None:
            models_to_test = list(self.ENHANCED_MODELS.keys())
        
        print(f"\nğŸ“‹ å°†æµ‹è¯•ä»¥ä¸‹å¢å¼ºæ¨¡å‹:")
        for model_key in models_to_test:
            model_config = self.ENHANCED_MODELS[model_key]
            print(f"   {model_key}: {model_config['description']}")
            print(f"      è¯´æ˜: {model_config['notes']}")
        
        total_start_time = time.time()
        results = []
        
        for i, model_key in enumerate(models_to_test, 1):
            print(f"\n{'='*60}")
            print(f"ğŸ“Š è¿›åº¦: {i}/{len(models_to_test)} - {model_key}")
            print(f"{'='*60}")
            
            model_config = self.ENHANCED_MODELS[model_key]
            result = self.train_enhanced_model(
                model_key, model_config, train_texts, train_labels,
                test_texts, test_labels, hierarchy, results_dir, training_config
            )
            results.append(result)
            
            # ä¿å­˜ä¸­é—´ç»“æœ
            interim_df = pd.DataFrame(results)
            interim_df.to_csv(results_dir / "enhanced_interim_results.csv", index=False, encoding='utf-8')
        
        total_time = time.time() - total_start_time
        self.generate_enhanced_comparison_report(results, data_info, total_time, results_dir)
        
        return results, results_dir
    
    def generate_enhanced_comparison_report(self, results, data_info, total_time, results_dir):
        """ç”Ÿæˆå¢å¼ºç‰ˆå¯¹æ¯”æŠ¥å‘Š"""
        print(f"\nğŸ“Š ç”Ÿæˆå¢å¼ºç‰ˆå¯¹æ¯”æŠ¥å‘Š...")
        
        results_df = pd.DataFrame(results)
        results_df = results_df.sort_values('accuracy', ascending=False)
        
        results_df.to_csv(results_dir / "enhanced_comparison_results.csv", index=False, encoding='utf-8')
        
        report = {
            'experiment_info': {
                'experiment_type': 'Enhanced Chinese BERT Model Comparison with Data Augmentation',
                'timestamp': datetime.now().isoformat(),
                'total_time_hours': total_time / 3600,
                'data_info': data_info,
                'enhancement_settings': {
                    'augmentation_enabled': self.enable_augmentation,
                    'balance_enabled': self.balance_data,
                    'target_samples_per_class': self.target_samples_per_class
                },
                'python_version': f"Python {'.'.join(map(str, __import__('sys').version_info[:3]))}",
                'pytorch_version': torch.__version__
            },
            'results': results_df.to_dict('records'),
            'summary': {
                'best_model': results_df.iloc[0]['model_name'] if len(results_df) > 0 else None,
                'best_accuracy': results_df.iloc[0]['accuracy'] if len(results_df) > 0 else 0,
                'models_tested': len(results_df),
                'successful_models': len(results_df[results_df['status'] == 'success']),
                'failed_models': len(results_df[results_df['status'] == 'failed']),
                'avg_improvement': self._calculate_improvement(results_df)
            }
        }
        
        with open(results_dir / "enhanced_comparison_report.json", 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ‰ å¢å¼ºç‰ˆæ¨¡å‹å¯¹æ¯”å®Œæˆ!")
        print(f"ğŸ“ˆ ç»“æœæ€»ç»“:")
        print(f"   æ€»è€—æ—¶: {total_time/3600:.2f} å°æ—¶")
        print(f"   æˆåŠŸæ¨¡å‹: {report['summary']['successful_models']}/{report['summary']['models_tested']}")
        print(f"   æ•°æ®å¢å¼º: {'âœ“' if self.enable_augmentation else 'âœ—'}")
        print(f"   æ•°æ®å¹³è¡¡: {'âœ“' if self.balance_data else 'âœ—'}")
        
        if len(results_df) > 0:
            successful_results = results_df[results_df['status'] == 'success']
            
            if len(successful_results) > 0:
                print(f"\nğŸ† å¢å¼ºæ¨¡å‹æ’å (æŒ‰å‡†ç¡®ç‡):")
                for i, (_, row) in enumerate(successful_results.iterrows(), 1):
                    print(f"   {i}. {row['description']}")
                    print(f"      å‡†ç¡®ç‡: {row['accuracy']:.4f} ({row['accuracy']*100:.2f}%)")
                    print(f"      Top-3: {row['top_3_accuracy']:.4f} ({row['top_3_accuracy']*100:.2f}%)")
                    print(f"      è®­ç»ƒæ—¶é—´: {row['training_time_minutes']:.1f} åˆ†é’Ÿ")
                    print(f"      å¢å¼ºè¯´æ˜: {row['notes']}")
                    print()
        
        print(f"\nğŸ“ è¯¦ç»†ç»“æœä¿å­˜åœ¨: {results_dir}")
    
    def _calculate_improvement(self, results_df):
        """è®¡ç®—ç›¸æ¯”åŸºå‡†æ¨¡å‹çš„æ”¹è¿›"""
        # è¿™é‡Œå¯ä»¥æ·»åŠ ä¸åŸå§‹æ¨¡å‹å¯¹æ¯”çš„é€»è¾‘
        # æš‚æ—¶è¿”å›å¹³å‡å‡†ç¡®ç‡
        successful = results_df[results_df['status'] == 'success']
        if len(successful) > 0:
            return successful['accuracy'].mean()
        return 0.0


def main():
    """ä¸»å‡½æ•° - å¢å¼ºç‰ˆè®­ç»ƒæµç¨‹"""
    print("ğŸš€ å¢å¼ºç‰ˆä¸­æ–‡BERTæ¨¡å‹è®­ç»ƒç³»ç»Ÿ")
    print("ğŸ¯ é›†æˆæ•°æ®å¢å¼ºä¸é¢„å¤„ç†åŠŸèƒ½")
    print("=" * 60)
    
    # åˆ›å»ºæ•°æ®å¤„ç†å™¨
    print("ğŸ”§ åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨...")
    data_processor = EnhancedJobDataProcessor(
        job_synonyms_path="job_synonyms.json"  # å¦‚æœæœ‰çš„è¯
    )
    
    # åˆ›å»ºå¢å¼ºè®­ç»ƒå™¨
    trainer = EnhancedModelTrainer(
        data_processor=data_processor,
        enable_augmentation=True,      # å¯ç”¨æ•°æ®å¢å¼º
        balance_data=True,            # å¯ç”¨æ•°æ®å¹³è¡¡
        target_samples_per_class=8    # æ¯ç±»ç›®æ ‡æ ·æœ¬æ•°
    )
    
    print("é€‰æ‹©æµ‹è¯•æ¨¡å¼:")
    print("1. å¢å¼ºç‰ˆå®Œæ•´æµ‹è¯• (æ¨è)")
    print("2. å¢å¼ºç‰ˆå¿«é€Ÿæµ‹è¯•")
    print("3. æ•°æ®å¢å¼ºæ•ˆæœå¯¹æ¯”")
    print("4. åªæµ‹è¯•æœ€ä½³æ¨¡å‹")
    
    choice = input("è¯·è¾“å…¥é€‰æ‹© (1-4): ")
    
    if choice == "1":
        models_to_test = list(trainer.ENHANCED_MODELS.keys())
        max_samples = None
    elif choice == "2":
        models_to_test = list(trainer.ENHANCED_MODELS.keys())
        max_samples = 10000
    elif choice == "3":
        # å¯¹æ¯”å¢å¼ºå‰åæ•ˆæœ
        models_to_test = ['hfl_roberta_enhanced']
        max_samples = 8000
    elif choice == "4":
        models_to_test = ['hfl_roberta_enhanced']
        max_samples = 15000
    else:
        print("æ— æ•ˆé€‰æ‹©ï¼Œä½¿ç”¨æ¨èé…ç½®")
        models_to_test = list(trainer.ENHANCED_MODELS.keys())
        max_samples = 15000
    
    csv_path = "newjob1_sortall.csv"
    if not os.path.exists(csv_path):
        print(f"âŒ æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶: {csv_path}")
        print("è¯·ç¡®ä¿æ•°æ®æ–‡ä»¶åœ¨å½“å‰ç›®å½•ä¸‹")
        return
    
    print(f"\nğŸ¯ å³å°†è¿è¡Œå¢å¼ºç‰ˆè®­ç»ƒ:")
    print(f"   æ•°æ®æ–‡ä»¶: {csv_path}")
    print(f"   æ•°æ®å¢å¼º: âœ“")
    print(f"   æ•°æ®å¹³è¡¡: âœ“")
    print(f"   æµ‹è¯•æ¨¡å‹: {len(models_to_test)} ä¸ª")
    if max_samples:
        print(f"   æ ·æœ¬é™åˆ¶: {max_samples:,}")
    
    confirm = input(f"\nç¡®è®¤å¼€å§‹è®­ç»ƒ? (y/N): ")
    if confirm.lower() != 'y':
        print("è®­ç»ƒå·²å–æ¶ˆ")
        return
    
    try:
        # è¿è¡Œå¢å¼ºç‰ˆå¯¹æ¯”
        results, results_dir = trainer.run_enhanced_comparison(
            csv_path, models_to_test, max_samples
        )
        
        print(f"\nğŸ¯ å¢å¼ºç‰ˆè®­ç»ƒå®Œæˆ! æŸ¥çœ‹è¯¦ç»†ç»“æœ: {results_dir}")
        
        # æ˜¾ç¤ºæœ€ä½³ç»“æœ
        if results:
            best_result = max(results, key=lambda x: x.get('accuracy', 0))
            if best_result['status'] == 'success':
                print(f"\nğŸ† æœ€ä½³æ¨¡å‹è¡¨ç°:")
                print(f"   æ¨¡å‹: {best_result['description']}")
                print(f"   å‡†ç¡®ç‡: {best_result['accuracy']:.4f} ({best_result['accuracy']*100:.2f}%)")
                print(f"   Top-3å‡†ç¡®ç‡: {best_result['top_3_accuracy']:.4f}")
                print(f"   Top-5å‡†ç¡®ç‡: {best_result['top_5_accuracy']:.4f}")
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()